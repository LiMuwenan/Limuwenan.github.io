### MySQL逻辑架构图

<img src="D:/JavaRookie/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%85%AB%E8%82%A1%E6%80%BB%E7%BB%93/MySQL.assets/image-20220215172853924.png" alt="image-20220215172853924" style="zoom: 33%;" />

##### 1、SQL语句执行流程

- **连接器**：负责跟客户端建立连接、获取权限、维持和管理连接；
- **查询缓存**：查询请求先访问缓存（`key`是查询的语句，`value`是查询的结果），如果命中直接返回。不推荐使用查询缓存，查询缓存的失效非常频繁，只要表更新会把缓存清除；
- **分析器**：对`SQL`语句做解析，包括词法分析和语法分析，判断`SQL`是否正确；
- **优化器**：在表里面有多个索引时，决定使用哪个索引；多表关联（`join`）的时候，决定各个表的连接顺序；
- **执行器**：执行语句，先判断用户有无查询权限，使用表定义的存储引擎；

> 长连接/短连接：数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接是指每次进行查询请求完之后都断开连接，下次请求需要重新建立连接。



### 0、存储引擎

##### 0.1 InnoDB

`InnoDB`是`MySQL`默认的存储引擎，支持事务，支持表级锁和行级锁，支持外键。`InnoDB`使用了`B+`树索引模型，所有数据都是存储在`B+`树中的。

实现了四个标准的隔离级别，默认的是可重复读。

使用`redo log`（重做日志）保证事务的持久性；使用`undo log`（回滚日志）保证事务的原子性；通过锁机制、MVCC等手段来保证事务的隔离性。保证了事务的持久、原子性、隔离性之后，一致性才能得到保障。

##### 0.2 MyISAM

`MyISAM`不支持事务，支持表级锁，不支持行级锁，表不支持外键，该存储引擎存有表的行数，`count`运算很快。适合频繁查询，不适合对于增删改要求高的情况。

##### 0.3 对比

- 是否支持事务

  `InnoDB`支持事务，`MyISAM`不支持事务；

- 是否支持外键

  `InnoDB`支持外键，`MyISAM`不支持外键；

- 是否支持行级锁

  `InnoDB`支持表级锁、行级锁，`MyISAM`只支持表级锁；

- 是否支持数据库异常崩溃后的安全恢复

  `MyISAM`不支持数据库异常崩溃后的安全恢复。`InnoDB`则可以通过`redo log`保证数据库恢复到崩溃前的状态。

##### 0.4 Memory

`Memory`存储引擎将所有数据都保存在内存，不需要磁盘`IO`。支持哈希索引，因此查找速度很快。`Memory`使用表级锁，因此并发写入的性能较低。





### 1、日志

##### 1.0 简述MySQL中的日志

- `redo log`：存储引擎级别的日志，关注于事务的恢复，在重启`mysql`的时候，根据`redo log`进行重做，从而使事务具有持久性；
- `undo log`：存储引擎级别的日志，保证数据的原子性，该`log`保存了事务发生之前的数据的一个版本，用于回滚，是`MVCC`的重要实现方法之一；
- `binlog`：数据库级别的日志，关注恢复数据库的数据；



##### 1.1、日志模块

- `redo log`（重做日志）

  `redo log`是`InnoDB`引擎特有的日志，是物理日志，记录的是在某个数据页上做了什么修改；关注于事务的恢复。循环写，空间固定会用完。

- `binlog`（归档日志）

  `binlog`是`MySQL`的`Server`层实现的，所有引擎都可以使用。`binlog`是逻辑日志，记录的是这个语句的原始逻辑。`binlog`是可以追加写的，文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
  
  > **只用 redo log，不要 binlog？**
  >
  > 不可以，`binlog`有着`redo log`无法替代的功能：
  >
  > - 一个是归档。`redo log`是循环写，写到末尾之后是要回到开头继续写的。这样历史日志就没法保留，`redo log`也就起不到归档的作用；
  > - 一个就是`MySQL`系统依赖于`binlog`。`binlog`作为`MySQL`一开始就有的功能，被用在了很多地方。其中`MySQL`高可用的基础，就是`binlog`复制；

**扩展：`binlog`和`redo log`写入机制**

> **binlog 写入机制**
>
> 主要写入逻辑：事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。
>
> 系统给`binlog cahce`分配了一片内存，每个线程一个。多个线程共用一份`binlog`文件。事务提交的时候，执行器把`binlog cache`里的完整事务写入到`binlog`中，并清空`binlog cahche`。这里的写`binlog`单单只是把`binlog`从`binlog cache`写入了`page cache`（内存中的页缓存）。而参数`sync_binlog`控制了是否把`page cache`中的`binlog`异步刷新到磁盘。
>
> - 参数为`0`时，表示每次提交事务，只进行写`page cache`，但不`fsync`；
>
> - 参数为`1`时，表示每次提交事务都会执行`fsyc`；
>
> - 参数为`N`时，表示每次提交事务写`page cache`，但累积`N`个事务后才`fsync`；
>
>   > 设置为`N`时，风险：如果主机发生异常重启，会丢失最近`N`个事务的`binlog`日志。
>
> **redo log 写入机制**
>
> 事务在执行过程中，生成的`redo log`是要先写到`redo log buffer`的。等事务提交时，才会执行`red log`写操作。写入策略三种，由`innodb_flush_log_at_trx_commit`参数控制：
>
> - 参数为`0`时，表示每次提交事务都只是把`redo log`留在`redo log buffer`中；
> - 参数为`1`时，表示每次提交事务都将`redo log`直接持久化到磁盘；
> - 参数为`2`时，表示每次提交事务都只是把`redo log`写到`page cache`；
>
> **为什么`binlog cache`是每个线程自己维护的，而`redo log buffer`是全局共用的？**
>
> - `binlog`是一种逻辑性的日志，记录的是一个事务完整的语句。当用来做主从同步，如果分散写，可能造成事务不完整，分多次执行，导致不可预知的问题。而`redo log`属于物理性的日志，记录的是物理地址的变动，因此，分散写也不会改变最终的结果。
> - `binlog`是以`statement`或者`row`格式存储的，而`redo log`是以`page`页格式存储的。`page`格式，天生就是共有的，而`row`格式，只跟当前事务有关。

**扩展：`binlog`三种格式**

> - `statement`：记录的是`SQL`语句；主从同步时可能会出现主备库数据不一致的情况（`delete`带`limit`，主库和从库走了不同的索引）。
> - `row`：记录的是：要操作的表和什么操作。占用空间大（删除`10`万条记录，需要把这个`10`万条记录都写到`binlog`中）。
> - `mixed`：`MqSQL`会自己判断这个条`SQL`语句是否可能引起主备不一致，如果有可能就用`row`格式，否则就用`statement`格式。



##### 1.2、undo log

`undo log`是回滚日志，在`MySQL`中，每条记录在更新的时候除了记录变更记录到`redo log`，还会同时记录一条回滚操作到`undo log`。记录上的最新值，通过回滚操作，都可以得到前一个状态的值，恢复到事务开始之前的状态，保证原子自性。

回滚日志`undo log`什么时候删除？

当没有事务需要用到这些回滚日志时，回滚日志会被删除。也就是当系统里没有比这个回滚日志更早的视图的时候。



##### 1.3、WAL

全称是`Write-Ahead Logging`，它的关键点就是先写日志，再写磁盘。当有一条记录需要更新的时候，`InnoDB`引擎会先把记录写到`redo log`，这个时候更新就算完成了。同时`InnoDB`引擎会在系统比较空闲的时候，将这个操作记录更新到磁盘里面。

> `InnoDB`先把记录写到`redo log`中，这也是一个写磁盘的过程，但是与更新过程不一样的是，更新过程是在磁盘上随机`IO`，费时；而写`redo log`是在磁盘上顺序`IO`，效率要高。



##### 1.4、crash-safe

`InnoDB`通过`redo log`保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力成为`crash-safe`。

> **如果`redo log`和`binlog`是完整的，`MySQL`是如何保证`crash-safe`的？**
>
> - 如果`redo log`中既有该事务的`prepare`，又有`commit`，则直接提交；
>
> - 如果`redo log`中只有`prepare`，则会拿着`XID`去`bin log`中找对应的事务，判断`binlig`中对应的事务是否完整，如果`binlog`完整则提交事务，否则回滚。
>
>   > 如何判断是否完整？
>   >
>   > 一个事务的`binlog`是有完整格式的：
>   >
>   > - `statement`格式的`binlog`，最后会有`COMMIT`；
>   > - `row`格式的`binlog`，最后会有一个`XID event`；
>   >
>   > 另外还有一个`binlog-checksum`参数，用来验证`binlog`内容的正确性。
>
> **XID**
>
> `XID`是`redo log`和`binlog`共同的数据字段，用于崩溃恢复的时候关联`redo log`和`binlog`。



##### 1.5、两阶段提交

为了保证`redo log`和`binlog`两份日志的逻辑一致，最终保证恢复到主备数据库的数据是一致的，将`redo log`的写入拆成了两个步骤：`prepare`和`commit`。

- 执行器调用存储引擎接口写入修改后的数据，引擎将这个新数据更新到内存中，同时将这个更新操作记录到`redo log`里面，此时`redo log`处于`prepare`状态；
- 存储引擎告知执行器执行完毕。执行器生成这个操作对应的`binlog`，并把`binlog`写入磁盘；
- 执行器调用引擎的事务提交接口，引擎把刚刚写入的`redo log`改成提交（`commit`）状态，更新完成。

> 场景：数据库的扩容，当需要增加备份库提高系统读数据库的能力时，常采取全量备份 + `binlog`实现。假如`binlog`和`red log`记录的事务的逻辑状态不一致，就会导致严重的主从数据库不一致问题。
>
> **为什么需要两阶段提交？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？**
>
> 因为对于`InnoDB`引擎来说，如果`redo log`提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务更新）。而如果`redo log`直接提交，然后`binlog`写入失败，`InnoDB`又回滚不了，就会出现`redo log`和`binlog`数据不一致问题。
>



##### 1.6、脏页/干净页

当内存数据页跟磁盘数据页内容不一致时，我们称这个内存也为“脏页”。

内存数据写入磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。



##### 1.7、何时刷脏页？

- `redo log`写满了，要`flush`脏页

  系统会停止所有更新操作，把`checkpoint`向前推进，这时就需要先将推进的区间对应的所有脏页都`flush`到磁盘上。这种情况要避免，因为整个系统就不能再接受更新了。

- 系统内存不足时，需要淘汰一些数据页。如果淘汰的是“脏页”，就要先将脏页写到磁盘；

- 系统空闲时；

- 正常关闭数据库时；



##### 1.8 脏页是如何产生的？

因为使用了`WAL`技术，这个技术会把数据库的随机写转化为顺序写，但副作用就是会产生脏页。





### 2、事务

##### 2.1、事务

事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在`MySQL`中，事务支持是在引擎层实现的。事务满足以下几个特性：

- 原子性`(Atomicity)`：一个事务中的操作要么全部成功，要么全部失败；
- 一致性`(Consistency)`：事务执行前后数据库的状态保持一致；
- 隔离性`(Isolation)`：多个并发事务对数据库进行操作，事务间互不干扰；
- 持久性`(Durability)`：事务执行完毕，对数据的修改是永久的，即使系统故障也不会丢失；



##### 2.2、事务隔离级别

当数据库上有多个事务同时执行的时候，就可能出现脏读`(dirty read)`、不可重复读`(non-repeatable read)`、

幻读`(phantom read)`的问题。为了解决这些问题，就有了“隔离级别”的概念。

> 脏读：读取到其他事务未提交的数据；
>
> 不可重复读：前后读取的记录内容不一致（两次读之间，数据被其他事务修改）；
>
> 幻读：前后读取的记录数量不一致（两次读之间，数据被其他事务删除或新增）；

- 读未提交`(read uncommitted)`：一个事务还没提交时，它的变更就能被别的事务看到；
- 读提交`(read committed)`：一个事务提交后，它的变更才能被别的事务看到；
- 可重复读`(repeatable read)`：一个事务在执行过程中看到的数据，总是和这个事务启动时看到的数据是一致的。当然在可重读隔离级别下，未提交变更对其他事务也是不可见的；
- 串行化`serializable`：对同一行记录进行读写会分别加读写锁。当出现读写锁冲突时，后访问的事务必须要等到前一个事务执行完，才能继续执行。

> 配置隔离级别方式：
>
> 将启动参数`transaction-isolation`的值设置为对应的隔离级别。



##### 2.3、读提交和可重复读都基于MVCC实现，区别？

- 在可重复读隔离级别下，只会在事务启动时创建一个视图，整个事务存在期间都用这个视图。

- 在读提交隔离级别下，会在每个`SQL`语句开始执行的时候创建一个新的视图。

因此对于可重复读，查询只能看到事务创建前就已经提交的数据；而对于读提交，查询能看到每个语句启动前已经提交的数据。

> `MySQL`的默认隔离级别是可重复读`(repeatable read)`，可以通过启动参数`transaction-isolation`的值设置成`READ-COMMITTED`。



##### 2.4、什么是MVCC

`MVCC`为多版本并发控制，即同一条记录在系统中可以存在多个版本。其存在目的是在保证数据一致性前提下提供一种高并发的访问性能。对数据读写在不加读写锁的情况下实现互不干扰，从而实现数据库的隔离性，在事务隔离级别为读提交和可重复读中使用到。

**事务如何实现`MVCC`？**

- 在`InnoDB`中，每个事务开始前会向系统申请一个事务`ID`（`transaction id`），`ID`是按申请顺序严格递增的；
- 事务在启动时，`InnoDB`会为事务构造一个数组，用来保存这个事务启动瞬间所有启动了但是还没提交的事务`ID`，数组中事务`ID`的最小值记为`up_limit_id`；
- 事务在更新一条语句时，比如`id = 1`修改为了`id = 2`，会把`id = 1`和该行之前的`row trx_id`写到`undo log`里，并且在数据页上把`id`的值改为`2`，然后修改这条语句的`transaction id`在该行行头；
- 当一个事务要查看一条数据时，必须先用该事务的`up_limit_id`与该行数据的`transaction id`做对比：
  - 如果`up_limit_id >= transaction id`，说明当前这个数据版本对应的事务在之前就提交了，那么可以看。
  - 如果`up_limit_id < transaction id`，则只能去`undo log`里去取。去`undo log`查找数据的时候，也需要对比`up_limit _id > transaction id`才返回数据。

> 每次事务更新数据的时候，都会生成一个新的数据版本，并且把`transaction id`赋值给这个数据版本的事务`ID`，记为`row tex_id`。



##### 2.5、长事务存在什么问题

长事务意味着系统里面会存在很老的事务视图。在这个事务提交前，回滚记录都需要保留，这会导致占用大量内存空间。除此之外，长事务还占用锁资源，可能会拖垮库。



##### 2.6 当前读

更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”`(current read)`。

简单来说，无论在哪种隔离级别的事务中，进行`update`操作都要在此时此刻的最新值上做修改。

> 除了`for update、lock in share mode、delete、insert、update`之外，`select`语句如果加锁，也是当前读。`insert`的时候，要判断主键是否已经存在，是否违反唯一约束，此时查看主键是否存在的查询也是当前读。
>
> 在查询于语句后面加上`lock in share mode`或`for update`，代表分别加了读锁（`S`锁，共享锁）和写锁（`X`锁，排他锁）。



##### 2.7 一致性读（快照读）

可重复读的核心就是一致性读`(consistent read)`。一致性读指的是语句执行之前或者在事务开始的时候会创建一个一致性视图，后面的读都是基于这个视图的，不会再去查询最新的值。

> `InnoDB`的行数据会有多个版本，每个版本都有自己的`row trx_id`，每个事务或语句有自己的一致性视图。一致性读会根据`row trx_id`和一致性视图确定数据版本的可见性。



##### 2.8、快照读和当前读

- 当前读

  当前读指的是`select for update`或者`select in share mode`，指的是在更新之前必须先查询当前的值，因此叫做当前读。

  > 因为`mysql`认为，`for update`已经给当前的行加了写锁，因此没必要再进行快照读，但是这样会造成幻读问题（`RR`隔离级别下）。

- 快照读

  快照读指的是语句执行之前或者在事务开始的时候会创建一个一致性视图，后面的读都是基于这个视图的，不会再去查询最新的值。



##### 2.9 幻读产生的原因？

即使把所有的记录都加上锁，还是阻止不了新插入的记录。行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之前的“间隙”。



##### 2.9、幻读如何解决？

- 将事务隔离级别设置为串行化；

- 可重复度隔离级别下，设置间隙锁（`Gap Lock`）；

  > 间隙锁：顾名思义，锁的是就是两个值之间的间隙，这样就确保了无法再插入新的记录。间隙锁是在可重复度隔离级别下才会生效的。



##### 2.10 引入间隙锁带来的问题？

- 会导致同样的语句锁住更大的范围，影响并发度

- 导致死锁

  本质上是因为间隙锁不互斥，这样依赖容易造成多个事务在并发执行下相互加间隙锁，导致死锁。



##### 2.11 丢失修改是什么？

数据被两个事务连续修改，导致第一个事务的修改被第二个事务覆盖丢失。





### 3、索引

索引是一种用于快速检索和查询数据的数据结构。常见的索引结构有：`B`树，`B+`树和`Hash`。在`MySQL`中有主键索引（聚簇索引）和非主键索引（二级索引）。

> - `B`树是一种自平衡的多叉树。每个节点都存储键值数据。其左子节点的关键字值小于该节点关键字值，且右子节点值大于该节点关键字值。
> - `B+`树基本定义和`B`树相同，不同点在于只有叶子节点存在键值数据，其他节点只存放`key`。
> - `B+`树所有叶子节点增加了一条引用链指向与它相邻的叶子节点，方便进行范围查询。
> - `B`树每一个节点都包含键值，查询效率比`B+`树高。



##### 3.0 数据库索引为什么用B+树不用红黑树或B树？

- 红黑树的出度为`2`，而`B+`树一般出度都很大，所以红黑树的树高比`B+`树大很多，`IO`次数也就更多，检索较慢；
- `B`树的每个节点都存放数据，而`B+`树只有叶子节点存放数据。所以相同的空间`B+`树可以存储的节点更多，整个树的高度就更低，`IO`次数就更少。
- `B+`树的叶子节点有链表相连，可以进行区间访问，而`B`树不支持。





##### 3.1、为什么引入索引？

为了提高数据查询的效率，利用索引可以在数据表中快速找到记录。



##### 3.2、InnoDB的索引模型

在`InnoDB`中，表都是根据主键顺序以索引的形式放的，这种存储方式的表成为索引组织表。`InnoDB`使用了`B+`树索引模型，所以数据都是存储在`B+`数中的。

每一个索引在`InnoDB`里面对应一颗`B+`数。



##### 3.3、MySQL常见索引类型

- 主键索引（聚簇索引）：数据表的主键列使用的就是主键索引。叶子节点存放的是整行数据；（`B+`树的叶子节点是`page`（页），一个页里面可以存多个行）
- 非主键索引（二级索引）：叶子节点内容是主键的值；
  - 唯一索引：唯一索引的属性列不能出现重复的数据，一张表允许创建多个唯一索引。（建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率）
  - 普通索引：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和`NULL`。
  - 前缀索引：前缀索引只适用于字符串类型的数据。前缀索引就是对字符串的前几个字符创建索引，相比普通索引更加节省空间；




##### 3.4、基于主键索引和普通索引的查询有什么区别？

基于主键索引的查询只需要搜索主键这颗`B+`树；

普通索引查询方式，需要先查二级索引树，拿到主键值，再到主键搜索树搜索一次，这个过程也称为回表。

> 非主键索引（普通索引）的查询一定会回表吗？
>
> 不一定，当要查询的字段全部命中索引，就不需要再回表查询。



##### 3.5 覆盖索引

覆盖索引是指一个索引包含或覆盖了所有需要查询的字段的值，不需要回表查询，也就是说索引本身存了对应的值。



##### 3.6 哈希索引和自适应索引

- 哈希索引：对于每一行数据计算一个哈希码，并将所有的哈希码保存在索引中，同时在哈希表中保存指向每个数据行的指针；只有`Memory`引擎显示支持哈希索引；哈希索引不支持范围查询，无法用于排序。
- 自适应索引：当某个索引值被使用的非常频繁时，会在`B+`树索引之上再创建一个哈希索引，称为自适应索引。



##### 3.7 联合索引和最左匹配原则

联合索引是指对表上的多个列的关键词进行索引。

对于联合查询的索引，如果精确匹配联合索引的左边连续一列或者多列，那么就会一直向右匹配直到遇到范围查询`(>、<、between、like)`就停止匹配。`MySQL`会对第一个索引字段数据进行排序，在第一个字段基础上，再对第二个字段排序。



##### 3.8 索引下推

在`MySQL5.6`之前，只能从根据最左前缀查询到的`ID`开始一个个回表。到主键索引上找出数据行，再对比字段值；

`MySQL5.6`引入的索引下推优化，可以在索引遍历过程中，`(InnoDB)`对索引包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。



##### 3.9 普通索引和唯一索引区别

**查询操作**

- 普通索引：查找到第一个满足条件的记录后，继续向后遍历，直到第一个不满足条件的记录；
- 唯一索引：由于索引定义了唯一性，查找到第一个满足条件的记录后，直接停止继续检索；

因为`InnoDB`的数据是按照数据页为单位来读写的。当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。

对于普通索引来说，要多做的那一次“查找和判断下一条记录的操作”，就只需要一次指针寻址和一次计算。

所以，对于查询操作，普通索引和唯一索引几乎没有区别。

**更新操作**

> 更新操作并不是直接对磁盘中的数据进行更新，而是先把数据页从磁盘读入数据页，再更新数据页。

- 普通索引：将数据页从磁盘读入内存，更新数据页；
- 唯一索引：将数据页从磁盘读入内存，判断是否唯一，再更新数据页；

由于`MySQL`中有个`change buffer`的机制，会导致`普通索引`和`唯一索引`在更新上有一定的区别。

`change buffer`的作用是为了减少随机磁盘访问（将数据从磁盘读入内存涉及随机`IO`的访问），提升更新性能。`change buffer`将数据写入原数据页的过程叫做`merge`。

- 普通索引

  - 如果需要更新的数据页在内存中，则会直接更新数据页；

  - 如果数据不在内存中，会先将更新记录在`change buffer`，在下次查询操作读取数据页时，顺带将数据`merge`到数据页中；

    > 除了访问这个数据页会触发`merge`外，系统有后台线程定期`merge`进行操作。在数据库正常关闭的过程中，也会执行`merge`操作。
    >
    > `change buffer`是可以持久化的数据，在内存上有拷贝，也会被写入到磁盘上。
    >
    > `change buffer`使用的是`buffer poll`里的内存，因此不能无限增大。可以通过`innodb_change_buffer-` `_max_size`参数进行动态设置。

- 唯一索引

  - 如果数据在内存中，就可以直接判断数据是否唯一，然后更新；
  - 如果不在内存中，需要先从磁盘读入内存，判断是否唯一，再更新；

对于唯一索引，`change buffer`是用不到的，及时数据页不在内存中，由于需要先判断数据是否唯一，还是需要先读出来。



##### 3.10 change buffer

`change buffer`是用于更新操作时缓存数据，减少随机磁盘访问。

当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，`InnoDB`会将这些更新操作缓存在`change buffer`中，这样就不需要从磁盘中读入这个数据页了。下次查询需要访问这个数据页的时候，将数据页读取内存，然后执行`change buffer`中与这个页有关的操作。`change buffer`将数据写入原数据页的过程叫做`merge`。

`change buffer`是可以持久化的数据，在内存中有拷贝，也会被写入到磁盘上。



##### 3.11 change buffer使用场景

`change buffer`适用于写多读少的场景。因为`change buffer`的主要目的就是将记录的变更缓存下来嘛，就是为了减少随机`IO`的次数。

如果是读多写少的话，更新操作刚记录到`change buffer`，就又来了个查询操作，就需要访问这个数据页，并立马触发`merge`过程。这样随机访问`IO`的次数不会减少，反而增加了`change buffer`维护的代价。



##### 3.12 change buffer 和 redo log区别

- `redo log`主要节省的是随机写磁盘的`IO`消耗（转成顺序写）；
- `change buffer`主要节省的是随机读磁盘的`IO`消耗；



##### 3.13 字符串字段常见索引方式

- 直接创建完整索引，这样可能比较占用空间；

- 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；

  这种方式需要判断出前缀的长度多少合适，根据业务来定，主要是看区分度多少合适；

- 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；

- 创建`hash`字段索引，查询性能稳定。但是有额外的存储和计算消耗，和倒序存储再创建索引一样，都不支持范围查询



##### 3.14 什么情况下无法使用索引或索引失效（全表扫描）

对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。包括：

- 对索引做显示的函数操作
- 隐式的字段类型转换
- 隐式的字符集转换



##### 3.15、什么时候需要创建索引？

- 被频繁查询的字段
- 需要频繁被作为查询条件的字段
- 查询过程中排序的字段创建索引
- 被频繁用于连接的字段





### 4、锁

根据加锁的范围，`MySQL`里面的锁大致可以分为全局锁、表级锁和行锁三类。

##### 4.1 全局锁

全局锁就是对整个数据库实例加锁。`MySQL`提供了一个加全局读锁的方法，命令是`Flush tables with read lock(FTWRL)`。全局锁的典型使用场景是，做全库逻辑备份（也就是把整库每个表都`select`出来存成文本）。

> 这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句都会被阻塞。
>
> 风险：
>
> - 如果在主库备份，在备份期间不能更新，业务停摆；
> - 如果在从库备份，备份期间从库不能执行主库同步过来的`binlog`，导致主从延迟；

> 官方自带的逻辑备份工具是`mysqldump`。当`mysqldump`使用参数`-single-transaction`的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于`MVCC`的支持，这个过程中数据是可以正常更新的。
>
> 但是这个方法只适用于所有的表使用事务引擎的库。

##### 4.2 表级锁

`MySQL`里面表级的锁有两种：一种是表锁，一种是元数据锁`(MDL)`。

- 表锁：语法是`lock tables ... read/write`，`lock tables`除了会限制别的线程的读写外，也限定了本线程接下来的操作对象（加读锁之后其他锁只能读不能写，本线程也不能写）；

- 元数据锁`(MDL)`：`MDL`的作用是防止`DDL`和`DML`并发的冲突，保证读写的正确性。`MDL`不需要显示访问，在访问一个表的时候会被自动加上。但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

  >  当对一个表做增删改查操作的时候，加`MDL`读锁；当要对表结构做变更操作的时候，加`MDL`写锁。

> - 读锁之间不互斥，因此你可以有多个线程同时对一张表进行增删改查；
> - 读写锁之前、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

##### 4.3 行锁

锁住某一行，如果表存在索引，那么记录是锁在索引上的。如果表没有索引，那么`InnoDB`会创建一个隐藏的聚簇索引加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但锁的开销也大，加锁慢，会出现死锁。

##### 4.4 两阶段锁

在`InnoDB`事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

##### 4.5 死锁

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

##### 4.6 如何解决数据库死锁

- **限制访问顺序**，对同一组资源，要按照尽量相同的顺序访问；

- **设置超时时间**，当查询的时间 达到 设定的锁等待超时时间后 放弃锁请求；

  这个超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置。

- **死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行；

  可以通过将参数`innodb_deadlock_detect`设置为`on`，表示开启这个逻辑。

##### 4.7 next-key lock

间隙锁和行锁合称`next-key lock`，每个`next-key lock`是前开后闭区间。`next-key lock`加锁过程是分为两步的，加上间隙锁，然后加行锁。

##### 4.8、加锁规则

- 查询过程中访问到的对象才会加锁，加锁的基本单位是`next-key lock`（前开后闭）
- 等值查询上`MySQL`的优化：如果是唯一索引，`next-key lock`会退化为行锁；如果不是唯一索引，需要访问到第一个不满足条件的值，此时`next-key lock`会退化为间隙锁。
- 范围查询：无论是否是唯一索引，范围查询都需要访问到不满足条件的第一个值为止。

##### 4.9 简述MySQL的共享锁和排他锁

- 共享锁也称为读锁，相互不阻塞，多个线程在同一时刻可以读取同一个资源而不相互干扰。

- 排他锁也称为写锁，会阻塞其他线程的读和写，防止在写入期间有其他线程读取正在写入的同一个资源。

##### 4,10 简述MySQL中的按粒度的锁分类

- 表级锁：对当前操作的整张表的加锁，实现简单，但并发性能低；
- 行锁：对操作的某一行进行加锁，如果存在索引，那么记录锁是锁在索引上的。如果表没有索引，`InnoDB`会创建一个隐藏的聚簇索引加锁。并发度高，但是加锁的开销也大，加锁慢，会出现死锁。
- 间隙锁：锁的是就是两个值之间的间隙，防止同一事物的两次当前读出现幻读的情况。
- `Next-key Lock`：行锁 + 间隙锁

##### 4.11 简述乐观锁和悲观锁

- 乐观锁

  乐观锁假设数据一般情况不会造成冲突，所以在数据提交的时才会通过一些机制来验证数据是否存在冲突；

- 悲观锁

  悲观锁就是总是假设存在并发冲突，所以在每次修改数据之前都先加锁，然后再进行读写。其他线程想要访问数据时，都需要阻塞挂起。

##### 4.12 乐观锁如何保证一致性？

乐观锁保持一致性主要有两种方法：

- 在数据属性中，增加版本号属性，进行比较，比较目前操作数据是否是最新版本；
- `CAS`，在数据修改过程中，采用`CAS(compare and swap)`机制保证在并发下的一致性；






### 5、数据库表

##### 5.1、表数据信息存在哪里？

表数据既可以存储在共享空间表里，也就是根数据字典放在一起。也可以单独存储在一个以`.ibd`位后缀的文件中。可以通过参数`innodb_file_per_table`控制。

一个表单独存储为一个文件更容易管理，在不需要的时候，通过`drop table`命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。



##### 5.2、表的结构信息存在哪里？

表结构定义占用的空间比较小，在`MySQL8.0`之前，表结构是存储在以为`.frm`为后缀的文件里。在`MySQL8.0`之后，允许把表结构的定义信息存在系统数据表中。

> 系统数据表，主要用于存储`MySQL`的系统数据，比如：数据字典、`undo log(默认)`等文件。



##### 5.3、为什么删除了表的一半数据，表文件大小没变化？

因为`delete`命令其实只是把记录的位置，或者数据页表示为了"可复用"，但磁盘文件的大小是不会变的。也可以认识是一种逻辑删除，所以物理空间没有实际释放，只是标记为可复用，所以表文件的大小不会变。



##### 5.4、如何删除，才能缩小表文件大小？

重建表，消除表因为进行大量的增删改操作而产生的空洞。使用如下命令：

- `alter table t engine=InnoDB`（`recreate`）

- `optimize table t`（等于`recreate + analyze`）

  其实不是建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了`MDL`读锁。

- `optimize table t`（等于`recreate + analyze`）

> 空洞就是那些被标记可复用，但是还没被使用的存储空间。
>
> 空洞如何产生？
>
> - 使用`delete`命令删除数据会产生空洞，标记为可复用；
> - 插入新的数据可能引起页分裂，也可能产生空洞（如果数据是随机插入的，就可能造成索引的数据页分裂）；
> - 修改操作，有时是一种先删后插的动作，也可能产生空洞；



##### 5.5、Online DDL

`Online DDL`就是为了收缩表空间，需要重建表。在重建表的过程中，旧表可以进行更新操作。



##### 5.6、在重建表的过程中，MySQL是怎么实现`online DDL`的？

因为重建表它会建立一个临时文件来替代原文件嘛。在生成临时文件的过程中，会将所有对原表的操作先记录在一个日志文件`(row log)`中，临时文件生成后，将日志文件中的操作应用到临时文件。然后用临时文件替代原表的数据文件。

> 重建表过程：
>
> - 建立一个临时文件，扫描表`A`主键的所有数据页；
> - 用数据页中表`A`的记录生成`B+`树，存储到临时文件中；
> - 生成临时文件的过程中，将所有对`A`的操作记录在一个日志文件（`row log`）中；
> - 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑上与表`A`相同的数据文件；
> - 用临时文件替换表`A`的数据文件；



##### 5.7 count(*)的实现方式

在不同的`MySQL`引擎中，`count(*)`有不同的实现方式。

- `MyISAM`引擎把一个表的总行数存在了磁盘上，所以执行`count(*)`的时候会直接返回这个总行数，效率很高；
- `InnoDB`执行`count(*)`的时候，需要把数据一行一行的从引擎里面读出来，然后累积计数；

> **为什么`MyISAM`可以直接记录一个数，而`InnoDB`需要一行行统计呢？**
>
> 因为`MyISAM`压根不支持事务，也不支持`MVCC`，所以所有线程看到的记录都是一样的，就可以记录一个总数，查询的时候直接返回。
>
> 但是`InnoDB`不行，由于支持`MVCC`，每一个事务查询到的数据是不一样的（每个事务都有自己的可见记录数，跟自己当前事务版本号有关），所以就需要一行一行统计记录数。
>
> **解决方案？**
>
> 用表存储总数，这样通过事务的可重复读可以保证数据一致。



##### 5.8 count效率排序

`count(字段) < count(主键id) < count(1) ≈ count(*)`-

- `count(字段)`：遍历整张表，需要一行行从记录里面读出字段，判断字段 `!= null`，按行累加；
- `count(id)`：遍历整张表，把每一行的`id`值都取出来，判断`!= null`，按行累加；
- `count(1)`：遍历整张表，但不取值。对于返回的每一行放一个数字`1`，按行累加；
- `count(*)`：不需要取字段，按行累加；

因为`count(*)`和`count(1)`不取字段值，减少往`server`层的数据返回（从引擎返回数据会涉及到解析数据行，以及拷贝字段的值），所以性能好。



##### 5.9 MySQL查询慢的原因？

- 查询被堵住了，比如表锁、行锁，或者是等`flash table`操作，`flush table`会等待正在运行的所有语句执行结束。
- 索引使用不当，没有走索引
- 一致性读：事务在执行过程中，其他事务更新过多版本未提交，就需要从当前`undo log`回退大量版本才能拿到启动时的快照



##### 5.10 delete、drop、truncate区别

- `delete`是每次从表中删除一行，并且同时将该行的函数操作记录在日志中保存以便进行回滚操作。
- `truncate`是一次性的从表中删除所有数据，删除操作不记入日志，不支持回滚。
- `drop`语句将表所占用的空间释放掉。



##### 5.11 误删数据，如何恢复？

- `DML`语句误删：造成数据不完整或丢失，可以使用工具`flashback`；（原理：修改`binlog`内容，拿回原库重放）
- `DDL`语句误删（`truncate`和`drop`）：全量备份 + 增量日志`binlog`；



##### 5.12 驱动表和被驱动表（了解）

驱动表是主动发起查询的表，被驱动表是根据`on`条件被动查询的表。



##### 5.13 join（了解）

`join`用于连接多个表，条件语句使用`on`而不是`where`。使用`join`语句性能比强拆成多个单表执行`SQL`语句性能要好。但是这个前提是：可以使用被驱动表的索引。否则扫描行数就会过多，尤其是在大表的`join`操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。

> 可以通过`explain`结果里面，`Extra`字段里面有没有出现`Block Nested Loop`字样。`BNL`算法不能使用被驱动表的索引。`Index Nested-Loop Join(NLJ)`可以使用被驱动表的索引。
>
> `BNL`算法优化：给被驱动表的关联字段加上索引，转成`BKA`算法。
>
> 不适合加索引的表，引入临时表，在临时表建立索引，代替被驱动表做查询。



##### 5.14 内存表和临时表区别（了解）

- 内存表

  指的是使用`Memory`引擎的表，建表语法是`create table...engine=memory`。表数据都保存在内存中，系统重启的时候会被清空，但是表结构还在。

- 临时表

  可以使用各种引擎类型。如果是使用`InnoDB`引擎或者`MyISAM`引擎的临时表，写数据的时候是写到磁盘上的。当然临时表也可以使用`Mmeory`引擎。

##### 5.15 介绍下临时表（了解）

适用场景：分库分表，查询到的数据在临时表中做聚合。

- 临时表建表语法是`create temporary table `；
- 内存表数据保存在内存中，重启会丢失，而临时表会写入磁盘；
- 临时表只能被创建它的`session`访问，对其他线程不可见；`session`结束后自动删除表结构和表数据；
- 临时表实际的存储文件名由`库名 + 表名 + serverid + 线程id`组成，所以可以临时表可以重名；
- `binlog`设置为`row`模式，临时表的操作不记录到`binlog`中；

##### 5.16 自增主键的作用？保存机制？

作用：让主键索引尽量的保持递增顺序插入，避免页分裂，使索引更紧凑；

保存机制：`MyISAM`引擎的自增值保存在数据文件中。`InnoDB`引擎的自增值，保存在内存中，`MySQL8.0`之后可以持久化到`redo log`；

**在什么场景下自增主键可能不连续？**

> - 唯一键冲突
> - 事务回滚
> - 自增主键的批量申请（对于批量插入数据的语句，为了不频繁申请`id`，`MySQL`会进行批量的申请，如果申请的`id`没有使用完，下次再申请时是从上次申请的`id`之后开始的，就会出现主键不连续）



##### 5.17、范式

**三大范式**

在关系型数据库中，关于数据表设计的基本原则、规则就称为范式`(Normal Form)`。

- 第一范式

  确保数据表中每个字段必须具有`原子性`，也就是说数据表中每个字段都是不能再拆分的。

- 第二范式

  确保每列都和主键完全依赖。

  > 例如：`成绩表`（学号，课程号，成绩）关系中，（学号，课程号）可以决定成绩，但是学号不能决定成绩，课程号也不能决定成绩，所以（学号，课程号）—> 成绩 就是`完全依赖关系`。

- 第三范式

  所有非主键字段不能依赖于其他非主键字段。也就是说非主键属性之间不能有依赖关系，必须相互独立。

**范式的优/缺点**

- 优点：消除数据库中的数据冗余；
- 缺点：可能降低查询效率。因为范式等级越高，设计出来的数据表就越多、越精细，进行数据查询的时候就可能需要关联多张表，效率比单表查询低，关联的`sql`语法写法不当的话也可能会出现索引无效的情况。

##### 5.18、增删改查语法

- `insert`：`INSERT INTO 表名(字段名1, 字段名2...) values (值1, 值2...)`
- `delete`：`DELECT FROM 表名 [WHERE 条件表达式] `、`TRUNCATE [TABLE] 表名`
- `update`：`UPDATE 字段名1, 字段名2,... FROM 表名 [where 条件表达式]`
- `select`：`SELECT 字段名1, 字段名2,... FROM 表名 [where 条件表达式]`

##### 5.19、MySQL的查询语法顺序

`where、group by、having、order by、limit`

##### 5.20、什么情况下适合分表？

针对存储了百万级乃至千万级条记录的大表。数据库在查询和插入的时间耗时太长，可以通过分表，将大表拆分成小表，提升数据库性能。

##### 5.21、关系型数据库和非关系型数据库区别？

- 关系型数据库一般都有固定的表结构，不容易扩展；非关系型数据库数据格式比较灵活，基于`k-v`、基于文档的等等，没有固定的表结构，方便扩展。

##### 5.22、分库分表怎么做？

对于分库，即将一个数据库拆分为多个库。可以通过水平拆分，或者垂直拆分的方式，将表进行拆分。一般可以采用中间件`Sharding-JDBC`进行分库分表。





### 6、高可用

##### 6.1 MySQL主从复制

`MySQL`提供主从复制功能，可以方便的实现数据库的多处备份，不仅能增加数据库的安全性，还能进行读写分离，提升数据库负载性能。

主从复制流程：

- 主库只要发生变化之后，会将记录写入`binlog`日志文件中；
- 从库启动一个`I/O thread`连接主库，请求`binlog`；
- 主库收到请求后，根据偏移量从本地读取`binlog`发送给从库；
- 从库拿到`binlog`后，写到本地文件，成为中转日志（`relay log`）；
- 从库的`sql thread`线程读取中转日志，解析出日志里的命令，并执行。

##### 6.2 双M结构

双M结构就是两个库互为主备关系，这样在切换的时候就不用再修改主备关系。

**问题**：循环复制，就是两个库不断循环执行对方的更新记录。

**解决**：

- 规定两个库的`server id`必须不同。
- 备库在执行主库同步的`binlog`时，生成与原`binlog`的`server id`相同的新的`binlog`。
- 每个库再收到从自己的主库发来的日志后，先判断`server id`，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。

##### 6.3 主备延迟

主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值。

**主备延迟的来源**

> - 备库所在机器性能比主库所在机器性能差；
> - 备库的压力大（大量的查询耗费了大量的`CPU`资源，影响同步速度）；
> - 大事务（因为主库必须等事务执行完才会写入`binlog`，再传给备库。如果一个事务执行时间过长，就会产生主备延迟）；
> - 大表的`DDL`，修改表结构之类的操作（后续的`DML binlog`发送到从库，需要等待`DDL`的`MDL`写锁释放）；

##### 6.4 主备切换策略

- 可靠性优先策略

  就是限制主备延迟小于一定时间才能进行操作。判断主备延迟小于某个值才进行下一步，否则持续重试这一步。

- 可用性优先策略

  不管主备延迟时间，直接切换。会导致主从数据不一致

##### 6.5 读写分离

**为什么要读写分离？**

> 为了分摊主库的压力，提高性能，提高可用性。
>
> 主从库负责各自的读写，极大程度缓解了锁的竞争。

**读写分离带来的问题？**

> 数据不一致问题。

##### 6.6 如何判断数据库是否正常？（了解）

- 查表判断

  建一个表辅助`MySQL`健康检查，每次都查询这个表的数据。问题：空间满了以后，读还是可用，但是写操作不可用。

- 更新判断

  用更新语句检查数据库读写是否有问题。常见的做法是放一个`timestamp`字段。问题：`update`需要的资源很少，即使是在`I/O`利用率`100%`也有机会获得`I/O`资源，执行成功。不能确保正常。

- `performace_schema`库，统计内部每一次`IO`请求的时间，设定阈值，请求时间超出阈值属于异常。

##### 6.7 MySQL如何保证主备一致的？

`MySQL`通过`binlog`实现主备一致。`binlog`记录了数据库中数据的所有变化，所以根据主库的`binlog`日志就能将主库的数据同步到从库中。在备份的过程中，主库会有一个专门的线程将主库的`binlog`发送给备库进行备份。

同步流程：

- 主库只要发生变化之后，会将记录写入`binlog`日志文件中；
- 从库启动一个`I/O thread`连接主库，请求`binlog`；
- 主库收到请求后，根据偏移量从本地读取`binlog`发送给从库；
- 从库拿到`binlog`后，写到本地文件，成为中转日志（`relay log`）；
- 从库的`sql thread`线程读取中转日志，解析出日志里的命令，并执行。





### 7、InnoDB

##### 7.1 InnoDB内存管理

`InnoDB`内存管理使用的是近似`LRU`算法，就是改进的`LRU`算法，不过核心思想还是淘汰最久未使用的数据。

在实现上，它是按照`5:3`的比例把整个`LRU`链表分成了`young`区和`old`区。新数据在一定时间内只能在`old`段的头部，当在`old`段保持了一定的时间后被再次访问才能升级到`young`。实质上是分了两段`LRU`，这样做的好处是防止大表扫描时，由于内存不足，内存数据被全量替换，导致正常业务查询的内存命中率急剧下降（而造成性能雪崩）。





### 8、查询性能优化

##### 8.1 Explain

`Explain`用于分析`SELECT`查询语句，可以通过分析`Explain`结果优化查询语句。

- `rows`：扫描行数；
- `key`：使用的索引；
- `select_type`：查询类型；
- `Extra`：额外信息；
  - `Using index`：使用了覆盖索引；
  - `Using filesort`：使用了外部的索引排序；
  - `Using temporary`：使用了临时表保存中间解结果；

##### 8.2 简述MySQL的优化流程

- 通过慢查询日志定位执行较慢的`SQL`语句；
- 利用`explain`对这些关键字段进行分析；
- 根据分析结果进行优化；

##### 8.3 SQL优化方法

核心就是避免全表扫描，多走索引。常见的优化方法：

- 尽量对利用较多的字段建立索引，即在`where、order by`涉及的列上建立索引；
- 尽量避免对字段进行表达式操作；（防止索引失效）
- 建立索引时多考虑最左匹配原则；（便于进行区间查询）



### 9、其他

##### 9.1 存储过程

存储过程可以看成是对一系列`SQL`操作的批处理。一般来说，普通的`SQL`语句需要先编译然后执行，而存储过程可以理解为为了完成特定业务而对已经编译后的`SQL`语句集进行批处理操作。

##### 9.2 MySQL数据库触发器

触发器简单来说就是监视某种情况，并触发某种操作。当触发器所在表上出现指定事件（`insert/update/delete`）时，可指定时间（`before/after`）执行特定事件（`insert/update/delete`）

##### 9.3 MySQL为什么要用自增`id`作为主键？

直接原因是其存储机制。`MySQL`采用数据页为单位进行数据存储，一个数据页大小默认为`16K`，如果一个数据页写满了，`MySQL`就会去申请一个新的数据页来存储数据。

- 如果主键为自增`id`的话，`mysql`在写满一个数据页的时候，直接申请另一个新数据页接着写就行了；
- 如果主键是非自增`id`，为了确保索引有序，`mysql`就需要将每次插入的数据都放到合适的位置上；

当往一个快满或已满的数据中插入数据时，新插入的数据会将数据页写满，`mysql`就需要申请新的数据页，并且将上个数据页中的部分数据挪到新的数据页上。这就造成了页分裂，这个大量移动数据的过程是会严重影响插入效率的。

##### 9.4 char 和 varchar的区别？

`char`的长度是不可变的，而`varchar`的长度是可变的。因此`char`效率高，`varchar`效率偏低。

##### 9.5 简述分布式id生成方法

`snowflake`算法：利用时间戳，机器`id`，当前数据库自增`id`进行拼接，生成的新的分布式`id`
