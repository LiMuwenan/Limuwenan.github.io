# 第1章 计算机网络和因特网

## 1.1 什么是因特网



## 1.1.1 具体构成描述

所有的设备称作**主机（host）**或**端系统（end system）**。

端系统通过**通信链路（communication link）**和**分组交换机（packet switch）**连接到一起。

通信链路由许多不同的物理媒体组成。这些物理媒体包括同轴电缆、铜线、光纤和无线电频谱。链路的传输速率以 比特/每秒（bit/s 或 bps） 度量。

数据在链路上传输是需要分段的，并为每段加上首部字节，称为**分组（packet）**。

端系统通过因特网服务提供商（Internet Service Provider，ISP）接入网络。

端系统、分组交换机和其他因特网不见都要运行一系列**协议（protocol）**。协议控制因特网中信息的接收和发送。TCP（Transmission Control Protocol，传输控制协议）和IP（Internet Protocol，网际协议）是因特网中两个最重要的协议。IP协议定义了路由器和端系统之间发送和接收的分组格式。

### 1.1.2 服务描述

与因特网相连的端系统提供了一个 **应用程序编程接口（Application Programming Interface，API）**，该API规定了运行在一个端系统上的软件请求因特网基础设施向运行在另一个端系统上的特定目的地软件交付数据的方式。

### 1.1.3 什么是协议

协议：定义了在两个或者多个通信实体之间交换的报文格式和次序，以及报文发送和/或接收一条报文或其他时间所采取的动作

## 1.2 网络边缘

手机、电脑等其他网络设备称为网络边缘设备

### 1.2.1 接入网

这里接入网（access network），这里指将端系统连接到边缘路由器（edge router） 的物理链路。边缘路由器是端系统到任何其他远程端系统的路径上的第一台路由器。



### 1.2.2 物理媒体

物理媒体划分为：导引型媒体（guided media）和非导引型媒体（unguided media）。

**1. 双绞铜线**

两根隔离的铜线绞合

绞合抗干扰



**2. 同轴电缆**

同轴电缆由两根铜导体组成，这两根铜是同心的而不是并行的。借助于这种结构及特殊的绝缘体和保护层，同轴电缆能够达到较高的数据传输速率。

**3. 光纤**

细而柔软，导引光脉冲，每个脉冲表示一个比特。

**4. 陆地无线电信道**



**5. 卫星无线电信道**





## 1.3 网络核心

网络核心：由互联网端系统的分组交换机和链路构成的网络（不包含边缘设备）

通过网络链路和交换机移动数据有两种基本方法：**电路交换（circuit switching）**和 **分组交换（packet switching）**

### 1.3.1 分组交换

在各种网络应用中，端系统彼此交换**报文（message）**。报文能够包含协议设计者需要的任何东西。

为了从源端系统向目的端发送一个报文，源将长报文划分为较小的数据块，称为 **分组（packet）**。在源和目的之间，每个分组都通过通信链路和 **分组交换机（packet switch）**（交换机主要有两类：路由器和链路层交换机）传送。

**1. 存储转发传输**

多数分组交换机在链路的输入端使用 **存储转发传输（store-and-forward transmission）**机制。存储转发机制是指在交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组。因此有了**转发时延**。

**2. 排队时延和分组丢失**

每个分组交换机有多条链路与之相连。对于每条相连的链路，该分组交换机具有一个 **输出缓存（output buffer or output queue）**，它用于存储路由器准备发往那条链路的分组。如果到达的分组需要传输到某条链路，但发现该链路正忙于传输其他分组，该到达分组必须在该输出缓存中等待。因此除了转发时延意外，分组还要承受输出缓存的 **排队时延（queue delay）**。

这些时延是变化的，变化的成都取决于网络种的拥塞成都。

因为缓存的大小是有限的，所以当等待传输的分组满了之后，将出现 **分组丢失（丢包）（packet lost）**，到达的分组或已经排队的分组之一将被丢弃。

**3. 转发表和路由选择协议**

在因特网中，每个端系统具有一个称为IP地址的地址。当源主机要向目的端系统发送一个分组时，源在该分组的首部包含了目的地的IP地址。当一个分组到达网络种的路由器时，路由器检查该分组的目的地址的一部分，并向一台相邻路由器转发给分组。每台路由器具有一个 **转发表（forwarding table）**，用于将目的地址（或目的地址的一部分）映射称为输出链路。当某分组到达一台路由器时，路由器检查该地址，并用这个目的地址搜索其转发表，以发现适当的输出链路。路由器则将分组导向该输出链路。

转发表通过路由选择协议自动进行设置

### 1.3.2 电路交换

在电路交换网络中，在端系统间通信会话期间，预留了端系统间通信沿路径所需要的资源（缓存，链路传输速率）。

在分组交换网络中，这些资源则不是预留的；会话的报文按需使用这些资源，其后归国可能是不得不等待（即排队）接入通信线路。

传统电话网络是电路交换网络的例子。在发送方能够发送信息之前，该网络必须在发送方和接收方之间建立一条连接。这个理这个连接被称为一条电路。当网络创建这种电路时，它也在连接期间在该网络链路上预留了恒定的传输速率（每条链路传输容量的一部分）。

**1. 电路交换网络中的复用**

链路中电路是通过 **频分复用（Frequency-Division Multiplexing，FDM）**或 **时分复用（Time-Division Multiplexing，TDM）**来实现的。

对于 FDM，链路的频谱由跨越链路创建的所有连接所共享。特别的是，在连接期间链路为每条连接专用一个频段。在电话网络中，这个频段通常具有4kHz的宽度。该频带的宽度称为 **带宽（bandwidth）**

对于TDM，时间被划分为固定区间的帧，并且每帧又被划分为固定数量的时隙。当网络跨越一条链路创建一条连接时，网络在每个帧中为该连接指定一个时隙。这些时隙专门由该连接单独使用，一个时隙（在每个帧内）可用于传输该连接的数据。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/自顶向下/FDMandTDM.png)

**2. 分组交换与电路交换对比**

### 1.3.3 网络的网络

网络结构1：分区 ISP 全部接入 全球承载 ISP

网络结构2：有多个全球承载 ISP

网络结构3：城市接入 ISP 接入省级 ISP 接入 国家级 ISP 再与第一层 ISP 相连接



## 1.4 分组交换网中的时延、丢包和吞吐量



### 1.4.1 分组交换网中的时延概述

当分组从一个结点（主机或者路由器）沿着这条路径到后继结点，该分组在沿途的每个节点经受了几种不同类型的时延。这些时延最为重要的是 **结点处理时延（nodal processing delay）**、**排队时延（queuing delay）**、**传输时延（transmission delay）**、**传播时延（propagation delay）**，这些时延累加就是 **结点总时延（total nodal delay）**

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/delay.png)

**1. 处理时延**

检查分组首部和决定将该分组导向何处所需要的时间是处理时延的一部分。处理时延也包括其他因素，如检查比特级别的差错所需要的时间，该差错出现在从上游结点向路由器A传输这些分组比特的过程中。路由器的处理时延通常是微秒或更低的数量级。在这种结点处理之后，路由器将该分组引向通往路由器B链路之前的队列。

**2. 排队时延**

在队列中，当分组在链路上等待传输时，它有一个排队的过程，这个就是排队时延。一个特定分组的排队时延长度将取决于先期到达的正在排队等待向链路传输的分组数量。如果该队列是空的，并且当前没有其他分组正在传输，则排队时延为0。另一方面，如果流量很大，并且许多其他分组也在等待传输，该排队时延将很长。

**3. 传输时延**

假定分组以先到先服务的方式传输，仅当所有已经到达的分组被传输后，才能传输刚到达的分组。用 $L$ 比特表示该分组的长度，用 $R \quad bps$ 表示从路由器A到路由器B的链路传输速率。例如，一条 $10Mbps$ 的以太网链路，速率 $R=10Mbps$；传输时延是 $L/R$。这是将所有分组的比特传输向链路所需要的时间。

**4. 传播时延**

一旦一个比特推向链路，该比特需要向路由器B传播。从该链路的起点到路由器B传播所需要的时间是传播时延。该比特以该链路的传播速率传播，该传播速率取决于物理媒体。传播时延等于两台路由器之间的距离除以传播速率，即 $d/s$。

**5. 传输时延和传播时延的比较**

传输时延是路由器将分组推出所需要的时间

传播时延是一个比特从一台路由器向零一台路由器传播所需要的时间

### 1.4.2 排队时延和丢包

### 1.4.3 端到端时延

### 1.4.4 计算机网络中的吞吐量

一个主机B向另一个主机B传输文件，在任何时间瞬间的**瞬时吞吐量（instantaneous throughput）**是主机B接收到该文件的速率

如果文件由 $N$ 比特组成，接收时间 $T$ 秒，则 **平均吞吐量（average throughput）** 是 $F/T \quad bps$。



## 1.5 协议层次及其服务模型

### 1.5.1 分层的体系结构

**1. 协议分层**

网络设计者以 **分层（layer）** 的方式组织协议以及实现这些协议的网络硬件和软件。

某一层会向它的上一层提供 **服务（service）**。

各层的所有协议被称为 **协议栈（protocol stack）**。因特网的协议栈由5个层次组成：物理层、链路层、网络层、运输层和应用层。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E5%8D%8F%E8%AE%AE%E5%88%86%E5%B1%82.png)

（1）应用层

网络应用程序以及它们的应用层协议存留的地方。

应用层协议分布在多个端系统上，一个段系统中的应用程序使用协议与另一个端系统在应用程序交换信息的分组。我们把这种位于应用层的信息分组称为报文。

（2）运输层

在应用程序端点之间传输应用层报文

运输层分组称为报文段

（3）网络层

网络层负责将称为数据报的网络层分组从一台主机移动到另一台主机

（4）链路层



（5）物理层

**2. OSI模型**

应用层、表示层、会话层、运输层、网络层、数据链路层和物理层

表示层：使通信的应用程序能够解释交换数据的含义，这些服务包括数据压缩和数据加密以及数据描述

会话层：提供了数据交换定界和同步功能

### 1.5.2 封装

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E5%B0%81%E8%A3%85%E6%B6%88%E6%81%AF.png)

封装概念。在发送主机端，一个应用层报文被 传输给运输层。运输层附上运输层首部信息，构成运输层报文段。运输层报文段即分装了应用层报文。运输层向网络层传递该报文段，网络层再加上网络层首部信息，构成网络层数据包。再传递到链路层，加上首部信息，构成链路层帧。

一个分组具有两种类型的字段：首部字段和有效载荷字段，有效载荷来自上一层分组






# 第2章 应用层

## 2.1 应用层协议原理

### 2.1.1 网络应用程序体系结构

应用程序体系结构（application architecture）由应用程序研发者设计，规定了如何在各种端系统上组织该应用程序。在组织应用程序体系结构时，应用程序研发者很可能利用现代网络应用的主流结构之一：客户-服务器结构或者P2P结构。

**客户-服务器体系结构（client-server architecture）**中，有一个总是打开的主机称为服务器，它服务于来自许多其他称为客户的主机的请求。

在一个 C/S 架构中，常常出现一台单独服务器资源不足的情况，为此可以配备大量的主机作为一个数据中心。

**P2P体系结构（P2P architecture）**中，对位于数据中心的专用服务器有最小的或者没有依赖。应用程序在间断连接的主机对之间使用直接通信，这些主机就是对等方。

### 2.1.2 进程通信

在操作系统的术语中，进行通信的实际上是 **进程（process）**而不是程序。当进程运行在相同的端系统上时，它们使用进程间通信机制相互通信。

在两个端系统上的进程通过跨越计算机网络交换报文（message）来相互通信，发送进程生成并向网络中发送报文；接收进行接收这些报文并可能向发送者进行响应。

**1. 客户和服务器进程**

对每对通信进程，我们通常将这啷个进程之一表示为客户，而另一个进程标识为服务器

**2. 进程与计算机网络之间的接口**

多数应用程序是由通信进程对组成，每对中的两个进程互相发送报文。从一个进程向另一个进程发送的报文必须通过下面的网络。进程通过一个称为 **套接字（socket）**的软件接口向网络发送报文和从网络接收报文，其是应用程序和运输层协议之间的接口。

套接字也称为应用程序和网络之间的 **应用程序编程接口（API）**。

应用程序开发者对于运输层的控制仅限于：选择运输层协议；可能可以设置运输层参数。

一旦应用程序开发者选择了一个协议，则该程序就建立在该协议提供的运输层服务之上。

**3. 进程寻址**

为了标识该接收进程，需要定义两种信息：主机的地址；定义在目的主机中的接收进程的标识符。

在因特网中，主机由 IP 地址标识。除了需要知道地址，发送进程还必须指定运行在接收主机上的接收进程（接受套接字），目的地端口号就是用来区分主机上的不同应用



### 2.1.3 可供应用程序使用的运输服务

套接字是应用程序和运输层之间的协议，开发应用时需要选择一个恰当的运输层协议提供服务。

运输层可提供的服务和应用程序的要求：可靠数据传输、吞吐量、定时和安全性



**1. 可靠数据传输**

如果一个协议提供了将正确且完整的数据提交给对方的数据交付服务，则认为该协议提供了 **可靠数据传输（reliable data transfer）**。运输层协议能够提供可靠数据传输，发送进程只要将其数据传递进套接字。

有些应用可以容忍数据部分丢失（视频图片丢失部分），称为 **容忍丢失应用（los**

**-tolerant）**

**2. 吞吐量**

运输层协议可以以某种特定的速率提供确保的可用吞吐量。该应用能够请求 r 比特/每秒的确保吞吐量，并且运输层协议确保吞吐量最少是 r。具有吞吐量要求的应用称为 **带宽敏感的应用**。

**3. 定时**

保证发送方注入套接字中的每个比特到达接收方的套接字不超过一个限制。

**4. 安全性**

加密发送

### 2.1.4 因特网提供的运输服务

**1. TCP**

[TCP服务](# 保留链接)包括面向连接服务和可靠数据传输服务。

- 面向连接的服务：在应用层数据报文开始传输之前，TCP让客户和服务器相互交换运输层控制信息（三次握手）。握手阶段使它们为大量分组的到来做好准备。在握手之后，一个TCP连接就子啊两个进程的套接字之间建立了。这是一条全双工连接。报文发送完之后拆除连接。
- 可靠的数据传送服务：通信进程能够依靠TCP无差错、按适当顺序交付所有发送的数据。当应用程序的一端将字节流传进套接字时，它能够依靠TCP将相同的字节流交付给接收方的套接字，而没有字节的丢失和冗余。

TCP协议还具有[拥塞控制机制](# 保留链接)。

**2. UDP**

[UDP](# 保留链接)是一种不提供必须要服务的轻量级运输协议，它仅提供最小服务。UDP是无连接的，因此在两个进程通信前没有握手过程。UDP协议提供一种不可靠数据传送服务，即不保证一定到达，也不保证报文的顺序性。

UDP没有拥塞控制机制。

**3. 因特网运输协议所不提供的服务**

<table>
    <tr>
    	<th>应用</th>
    	<th>应用层协议</th>
    	<th>支撑的运输协议</th>
    </tr>
    <tr>
		<th>电子邮件</th>
		<th>SMTP</th>
		<th>TCP</th> 
    </tr>
    <tr>
		<th>远程终端访问</th>
		<th>Telnet</th>
		<th>TCP</th> 
    </tr>
     <tr>
		<th>Web</th>
		<th>HTTP</th>
		<th>TCP</th> 
    </tr>
      <tr>
		<th>文件传输</th>
		<th>FTP</th>
		<th>TCP</th> 
    </tr>
      <tr>
		<th>流媒体</th>
		<th>HTTP</th>
		<th>TCP</th> 
    </tr>
      <tr>
		<th>网络电话</th>
		<th>SIP，RTP</th>
		<th>UDP，TCP</th> 
    </tr>
</table>

### 2.1.5 应用层协议

**应用层协议（application-layer protocol）**定义了运行在不同端系统上的应用程序如何互相传递报文。应用层协议定义了：

- 交换报文的类型（请求报文、响应报文）
- 各种报文类型的语法（各个字段的描述方式）
- 字段的语义
- 一个进程何时以及如何发送报文

## 2.2 Web和HTTP

### 2.2.1 HTTP概况

Web的应用层协议是 **超文本传输协议（HyperText Transfer Protocol，HTTP）**。

HTTP由两个程序实现：一个客户程序和一个服务器程序。

**Web页面**由对象组成，一个对象只是一个文件（HTML，JPEG等等），可以通过一个 URL 寻址。多数Web应用包含一个HTML基本文件以及几个引用对象。**Web浏览器**实现了HTTP客户端。**Web服务器**实现了HTTP服务端，用于存储Web对象。

HTTP定义了Web客户向Web服务器请求Web页面的方式，以及服务器向客户传送Web页面的方式。

HTTP客户首先发起一个与服务器的TCP链接，一旦建立，该浏览器和服务器进程就可以通过套接字接口访问TCP。

HTTP不保存客户信息，因此短短几秒钟用户进行两次请求，服务器都会做出反应，重新发送请求对象。因此说HTTP是一个无状态协议。

### 2.2.2 非持续连接和持续连接

如果每个请求和响应对经过一个单独的TCP连接发送，那么称为非持续连接。

如果使用同一个TCP连接发送，那么称为持续连接。

**1. 非持续连接HTTP**

往返时间（Round-Trip Time）：一个短分组从客户到服务器然后再返回给客户所花费的时间。RTT包括分组传播时延、分组在中间路由器和交换机上的排队时延以及分组处理时延。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E6%8E%A5%E6%94%B6HTML%E6%89%80%E9%9C%80%E6%97%B6%E9%97%B4.png)

一次请求时间包含两个RTT时间和一个文件传输时间

**2. 采用持续连接的HTTP**

使用同一个连接

### 2.2.3 HTTP报文格式

分为请求报文和响应报文

**1. HTTP请求报文**

```http
GET /somedir/page.html HTTP/1.1
HOST:www.someschool.edu
Connection:close
User-agent:Mozilla/5.0
Accept-language:fr
```

报文由5行组成，每行由一个回车和换行符结束。HTTP请求报文第一行叫做**请求行（require line）**，其后继的行叫做 **首部行（header line）**。

请求行包括三个字段：方法字段、URL字段、HTTP版本字段。方法字段可以包括：GET、POST、HEAD、PUT、DELETE。

首部行Host指明了对象所在的主机；Connection使用close希望每次都关闭连接，使用非持续连接；User-agent标明使用的浏览器；Accept-language标识接收语言

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/HTTP%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png)

使用GET方法时，实体主体是空的。POST请求会携带表单信息。

**2. HTTP响应报文**

```http
HTTP/1.1 200 OK
Connection:close
Date: Tue, 09 Aug 2011 15:44:04 GMT
Server: Apcahe/2.2.3(CentOS)
Last-Modified: Tue, 09 Aug 2011 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html

(data data ...)
```

响应报文分为三个部分：一个初始 **状态行（status line）**，6个 首部行（header line），然后是 **实体体（entity body）**。实体部分是报文的主要部分

状态行指示服务器使用HTTP/1.1，并且一切正常；Connection表示发送完报文后关闭TCP连接；Date表示服务器产生并并发送该响应报文的时间；Server表示该报文由Apache服务器产生；Last-Modified表示对象创建或最后的修改日期；Content-Length表示被发送对象中的字节数；Content-Type表示实体体中的对象是HTML文本

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/HTTP%E5%93%8D%E5%BA%94%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png)

状态码：

- 200 请求成功
- 301 对象被转移，Location首部有新的URL
- 400 错误码
- 404 请求不在服务器上
- 505 服务器不支持请求报文使用的HTTP协议版本

### 2.2.4 用户与服务器的交互： cookie

cookie技术有四个组件：

- 在HTTP响应报文中的一个cookie首部行
- 在HTTP请求报文中的一个cookie首部行
- 在用户端系统中保留一个cookie文件，并由用户的浏览器进行管理
- 位于Web站点的一个后端数据库

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/cookie%E8%B7%9F%E8%B8%AA%E7%8A%B6%E6%80%81.png)

用户端和服务端cookie获取和识别流程：

1. 用户第一次访问该服务器，发送一个HTTP请求报文
2. 服务器对该用户进行一个标识，并返回该标识的cookie信息。
3. 用户收到这个标识cookie，用户浏览器会将这个cookie保存起来。
4. 当用户再次请求网站，浏览器将找到已保存的cookie信息，然后发送给服务器，服务器再返回信息。

### 2.2.5 Web缓存

**Web缓存器（Web cache）**也叫做 **代理服务器（proxy server）**，它是能够代表初始Web服务器来满足HTTP请求的网络实体。

可以配置用户浏览器，使所有用户的HTTP请求先指向缓存服务器，缓存服务器对请求报文进行识别。如果该服务器上存储了要请求的对象，那直接返回；如果没有，缓存服务器再与后台服务器建立TCP连接请求该对象。

通过使用 **内容分发网络（Content Distribution Network , CDN）**，降低主服务器压力，在各地建立 CDN服务器，提高用户请求资源的速率，降低供应商成本。

### 2.2.6 条件GET方法

Web缓存服务器上的内容可能已经是旧的。HTTP协议提供了一种机制，允许缓存服务器证实它的对象是最新的。这种机制就是 **条件GET方法**：如果请求报文使用了GET方法，并且请求报文中包含了一个 `If-Modified-Since` 首部行，那么就是一个条件请求。

## 2.3 文件传输协议：FTP

在一个典型的FTP会话中，用户坐在一台主机前面，向一台远程主机传输或接收文件。为使用户能够访问它的远程账户，用户必须提供一个用户标识和口令。

HTTP和FTP都是文件传输协议，它们都运行在TCP上。

FTP使用了两个TCP连接：一个是 **控制连接（control connection）**，一个是 **数据连接（data connection）**。控制连接用于在两个主机之间传输控制信息，比如用户标识、口令、改变远程目录的命令以及存放和获取文件的命令；数据连接用于实际的发送一个文件。

控制连接使用21端口，数据连接使用20端口

因为FTP使用了一个独立的控制连接，所以我们也成FTP的控制信息是 **带外（out-of-band）**传送的。因此HTTP也可以说是 **带内（in-band）**的。

**1. FTP命令和回答**

FTP命令是以7比特的ASCII格式在控制连接上传送，使用回车换行符进行连续命令的区分。每个命令由4个大写ASCII码字符组成

常见命令：

- USER username：用于向服务器传送用户标识
- PASS password：用于向服务器发送用户口令
- LIST：用于请求服务器回送当前远程目录中的所有文件列表。文件列表由非持续的数据连接传送
- RETR filename：用于从远程主机当前目录检索（get）文件。该命令引起远程主机发起一个数据连接，并经该连接发送文件
- STOR filename：在远程主机的当前目录存放文件（put）

常见回答：

- 331 Username OK， Password required（需要口令）
- 125 Data connection already open; transfer starting（数据连接已经打开，开始传送）
- 425 Can't open data connection
- 452 Error writing file

## 2.4 因特网中的电子邮件

邮件系统有三个组成部分：用户代理（user agent）、邮件服务器（mail server）、简单邮件传输协议（Simple Mail Transfer Protocol，SMTP）

邮件服务器形成了电子邮件体系结构的核心。每个接收方在其中的某个邮件服务器上有一个邮箱。

用户的邮箱管理和维护者发送给他的报文。

一个典型过程：从发送方的用户代理开始，传输到发送方的邮件服务器，再传输到接收方的邮件服务器，然后在这里被分发到接收方的邮箱中。

SMTP有两个部分：运行在发送方邮件服务器的客户端和运行在接收方邮件服务器的服务器端。每台邮件服务器既运行SMTP的客户端也运行SMTP的服务器端。

如果接收方服务器没有开机，邮件就会在发送方的邮件服务器保留并不断尝试，只有一个阈值而丢弃。

### 2.4.1 SMTP

SMTP一般不使用中间的邮件服务器，直接从发送方邮件服务器发送到接收方的服务器。

客户SMTP（发送方服务器上）在25号端口建立一个到接收方服务器的TCP连接，如果服务器没有开机，客户会稍后尝试。一旦连接会执行应用层的握手动作。在SMTP握手阶段，SMTP客户指示发送方的邮件地址和接收方的邮件地址，然后开始发送报文。

### 2.4.2 与HTTP对比

共同点：

- 两台主机传送文件

不同点：

- HTTP是一个拉取协议，SMTP是推送协议
- SMTP要求每个报文和体使用7比特ASCII格式，HTTP没有限制
- 对于既包含文本又包含图形的文档，HTTP把每个对象封装到自己的HTTP响应报文中，SMTP则把所有的保温对象放在一个报文中

### 2.4.3 邮件报文格式和MIME

邮件自身报文格式，不是握手协议格式

```smtp
From: alice@crepes.fr
To: bob@hanburger.edu
Subject: Searching for the meaning of life
```

一个首部必须包含From和To，可能包含Subject

报文首部之后，紧接着一个空白行，然后是以ASCII格式标识的报文体。

### 2.4.4 邮件访问协议

 用户A的代理将邮件推入用户A的邮件服务器，A服务器会重复尝试将报文发送给B的邮件服务器，等待用户B拉取。

这里的拉取操作使用了 **第三版的邮局协议（Post Office Protocol-Version 3，POP3）**和 **因特网邮件访问协议（Internet Mail Access Protocol，IMAP）**以及HTTP

**1. POP3**

当用户代理打开了一个到邮件服务器端口110上的TCP连接后，POP3就开始工作了。POP3按照三个阶段进行工作：特许（authorization）、事务处理以及更新。在第一个阶段：用户代理发送用户名和口令鉴别用户；第二个阶段：用户代理取回报文，同时可以对报文做删除标记，取消删除标记，以及获取统计信息；第三个阶段，它出现在用户发出quit命令之后，目的是结束POP3对话，这时邮件服务器会删除被标记的报文

POP3用户代理发出指令，服务器做出回答。结果可能有两种：+OK、-ERR

用户代理通常被配置为“下载并删除”或者“下载并保留”方式。

用户代理首先list请求邮件服务器列出所有存储的报文的长度，接着retr返回邮件，dele标记删除，quit退出，退出后就会删除标记的邮件。

下载删除方式不能多端同步，即在一台主机上接收邮件后，第二台主机上不能再接收。

**2. IMAP**

当用户使用POP3时，用户只能在本地创建层次文件夹，如果更换设备就需要重新创建。用户更希望在远程服务器上可以有层次文件夹。

IMAP服务器把每个报文与文件夹联系起来；当报文第一次到达服务器时，它与收件人的INBOX相关联。收件人则能够把邮件移动一个新的、用户创建的文件夹中。IMAP为用户提供了创建文件夹以及移动文件的命令，还提供了在远程文件夹中查询邮件的命令，IMAP还维护了一个会话的用户状态信息（文件夹的名字以及哪些报文与哪些文件夹关联）。

IMAP允许用户代理获取报文组件的命令。当用户在低带宽条件下，可能不想取回邮件中的视频、音频等内容，IMAP就可以做到。

**3. Web电子邮件**

用户代理使用HTTP请求从邮件服务器取回邮件；用户代理向邮件服务器发送邮件也使用HTTP

## 2.5 DNS：因特网的目录服务

主机的一种标识方法是使用主机名（cnn.com、www.yahoo.com等等）

然后这并不能识别具体地址，主机还可以使用IP地址进行标识

### 2.5.1 DNS提供的服务

主机名（域名）转换为IP地址。

这就是 **域名系统（Domain Name System，DNS）**的和主要任务。DNS是：一个由分层的DNS服务器实现的分布式数据库；一个使得主机能够查询分布式数据库的应用层协议

DNS服务器通常运行BIND（Berkeley Internet Name Domain）软件的UNIX机器。

DNS协议运行在UDP上，使用53端口

用户请求一个域名地址，浏览器将这个域名传给DNS应用客户端，DNS客户端向DNS服务器发送一个包含主机名的请求，DNS客户端会收到一个对应主机名的IP地址答文，浏览器接收到IP地址后就会发送HTTP请求。

一般在附近都会有DNS服务器

DNS提供的其他服务：

- 主机别名
- 邮件服务器别名
- 负载分配

### 2.5.2 DNS工作机理概述

工作流程：

1. 用户客户端需要解析域名，应用程序调用DNS客户端
2. DNS客户端将该域名发送到网络中，使用UDP经过53端口
3. 等待一段时间用户主机上的DNS客户端就会接收到一个IP地址报文

单一的DNS服务器缺点和问题：

- 单点故障
- 通信容量
- 远距离集中式数据库
- 维护域名数据库

**1. 分布式、层次数据库**



**2. DNS缓存**



### 2.5.3 DNS记录和报文

共同实现DNS分布式数据库的所有DNS服务器存储了资源记录（Resource Record，RR），RR提供了主机名到IP地址的映射。

资源记录包含一个四元组：（Name、Value、Type、TTL）

TTL：该记录的生存时间，什么时候从缓存中删除

Name和Value的值取决于Type

- 如果Type=A，则Name是主机名，Value是该主机名对应的IP地址
- 如果Type=NS，则Name是个域（foo.com），而Value是个知道如何获得该域中主机IP地址的权威DNS服务器的主机名
- 如果Type=CNAME，则Value是别名为Name的主机对应的规范主机名
- 如果Type=MX，则Value是个别名为Name的邮件服务器的规范主机名

**1. DNS报文**

DNS查询和回答报文具有相同的格式

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/DNS%E6%8A%A5%E6%96%87.png)

- 前12字节是首部：
  - 标识符16比特，用于标识该查询；
  - 标志字段，1比特的“查询（0）/回答（1）”标志；请求权威DNS时，1比特的权威标志位被放在回答报文中；如果没有查询到，将设置1比特的“希望递归”查询标志，如果DNS服务器支持递归查询，回答报文会有1比特的“递归可用”标志位。
  - 数量字段：后面数据区域的数量
- 问题区域：
  - 包含正在进行查询的信息。名字字段，正在被查询的主机名；类型字段，指出有关改名字的正在被询问的问题类型
- 回答区域：
  - 包含了对最初请求的名字的资源记录。回答区域可以包含多条RR，因此一个主机名可以有多个IP地址
- 权威区域：包含了其他权威服务器的记录
- 附加区域：包含其他有帮助的记录

**2. 在DNS数据库中插入记录**

注册的登记机构

注册域名时，需要向该结构提供你的基本和权威DNS服务器的名字和ip地址

## 2.6 P2P应用



# 第3章 运输层

## 3.1 概述和运输层服务

运输层协议位运行在不同主机上的应用程序之间提供了逻辑通信功能。

运输层协议是在端系统中而不是路由器中实现的。在发送端，运输层将从发送应用程序进程接收到的报文转换成运输层分组，该分组称为运输层报文段。将应用报文划分为小块并为每一块添加运输层首部信息生成运输层报文段。运输层报文段在网络层封装成网络层报文段并发送。

### 3.1.1 运输层和网络层的关系

网络层提供了两个主机之间的逻辑通信。

运输层提供了运行在两个主机上的进程之间的逻辑通信。

### 3.1.2 因特网运输层概述

[UDP](# 保留链接)：用户数据报协议，不可靠无连接

[TCP](# 保留链接)：传输控制协议，可靠、面向连接。通过使用[流量控制、序号、确认和定时器](# 保留链接)来确保可靠性

TCP还提供[拥塞控制](# 保留链接)。

UDP和TCP最基本的责任是将两个端系统间IP的交付服务扩展为运行在端系统上的两个进程之间的交付任务。将主机间交付扩展到进程间交付的过程被称为 **[运输层的多路复用（transport-layer multiplexing）与 多路分解（demultiplexing）](# 3.2 多路复用和多路分解)**。UDP和TCP还可以通过在报文段首部添加[差错检查](# 保留链接)字段而提供完整性检查。

## 3.2 多路复用和多路分解

一个进程有一个或多个套接字，它相当于网络向进程传递数据和进程向网络传递数据的门户。因此，在接收主机中的运输层实例上并没有直接将数据交付给进程，而是将数据交给了一个中间的套接字。在任意时刻，在接收主机上不可能只有一个套接字，所以每个套接字都有一个唯一标识，用来标识是UDP还是TCP.

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E5%A4%9A%E8%B7%AF%E5%88%86%E8%A7%A3.png)

在接收端将运输层报文段中的数据交付到正确的套接字的工作称作 **多路分解**。

在发送端从不同的套接字中收集数据块，并为每个数据块装上首部信息（层层封装）从而生成报文段，然后将报文段传递到网络中，称作 **多路复用**。

多路复用要求：

- 套接字有唯一标识符
- 每个报文段有特殊字段来指示该报文段所要交付到的套接字
  - 这些特殊字段是 **源端口号字段（source port number field）** 和 **目的端口号字段（destination port number field）**。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E6%BA%90%E5%92%8C%E7%9B%AE%E7%9A%84%E7%AB%AF%E5%8F%A3.png)

在主机上每个套接字能够分配一个端口号，当报文段到达主机时，运输层检查报文段中的目的端口号，并将其定向到相应的套接字。然后报文段中的数据通过套接字进入其所连接的进程。

**1. 无连接的多路复用与多路分解**

UDP

一个UDP套接字是有一个二元组来全面标识的，该二元组包含一个目的IP地址和一个目的端口号。创建的报文中会包含源地址和源端口号。

只要目的IP地址和目的端口号相同就会进入同一个套接字。

**2. 面向连接的多路复用和多路分解**

TCP

TCP套接字由一个四元组标识，包含源IP地址、源端口号、目的IP地址、目的端口号。接收端使用这四个值将报文段分解到相应的套接字。

必须四元组都相同才能进入同一个套接字。

**3. Web服务器与TCP**



## 3.3 无连接运输：UDP

因为UDP在发送之前没有和接收方握手，所以说UDP是无连接的。

为什么选择UDP：

- 一些实时应用可以容忍数据丢失
- 无需建立连接，节省建立连接的时延
- 无连接状态，不需要维护与目标主机的连接状态，节省发送端资源
- 分组首部开销小，TCP20个字节，UDP8个字节

### 3.3.1 UDP报文段结构

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/UDP%E6%8A%A5%E6%96%87%E7%BB%93%E6%9E%84.png)

UDP首部四个字段：源端口号、目的端口号、长度、校验和。这四个字段都由两个字节组成

端口号的功能是到达目的服务器后方便进行分解，进入相应的套接字；长度表示在UDP报文段中的字节数（首部加数据）；接收方使用检验和检查报文中是否出现了差错，计算检验和时还包括IP首部的一些字段。

### 3.3.2 UDP检验和

UDP检验和提供了差错检测功能，用于确定当UDP报文段从源到达目的地移动时，其中的比特是否发生了改变。发送方的UDP对报文段中的所有16比特字的和进行反码运算，求和时遇到任何溢出都回卷（将溢出的1和后面的位相加），得到的结果被放在UDP报文段中的检验和字段。

将所有16比特字加起来，后进行反码运算，这个结果就是校验和。此时再将包括校验和在内的16比特字加起来，就是全1。如果接收方校验时产生了0，那么说明出现了差错。

```
0110 0110 0110 0000 + 0101 0101 0101 0101 + 1000 1111 0000 1100 = 0100 1010 1100 0010
```

在前面两位相加后

```
1011101110110101
```

再和第三个数相加的结果，溢出，将最前面的1拿出来和0110101011000001相加得到最终结果

```
10110101011000001
```

然后取反

因为无法确保传输链路中的可靠性（链路层协议可能提供了差错检测），因此UDP自己实现差错检测保证 **端到端原则**

UDP检测到错误后会丢失受损的报文段并可能给应用程序给出警告。

## 3.4 可靠数据传输原理

实现可靠数据传输需要依靠**可靠数据传输协议（reliable data transfer protocol）**

### 3.4.1 构造可靠数据传输协议

**1. 经完全可靠信道的可靠数据传输：rdt 1.0**

假设底层信道完全可靠，即不会有比特丢失等情况。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/rdt1.0.png)

发送方调用 rdt_send() 向接受发发送信息；分组到达接收方，调用 rdt_rev()，当想要向更高层传递数据时，调用 deliver_data()



**2. 经具有比特差错信道的可靠数据传输：rdt 2.0**

底层信道可能会使分组中的比特受损。

假定分组可以按发送顺序被接收。

像说话一样：发送方发送了一段报文，接收方可能使用 **肯定确认**或者 **否定确认**。这些控制报文使得发送发知道哪些内容被正确接收，哪些有错误需要重复。基于重传机制的可靠数据传输协议称为 **自动重传你请求（Automatic Repeat reQuest，ARQ）协议**

ARQ协议对于处理比特差错的情况：

- [差错检验](# 保留链接)：使接收方检测到何时出现了比特差错。第五章详细介绍。
- 接收方反馈：接收方返回 ACK 或者 NAK
- 重传：接收方收到信息有差错，则重传

当发送方处于等待确认信息状态时，不会从上层获得更多的数据。这被称为 **停等**

ACK和NAK确认信息也可能受损，需要差错检验和纠错。

受损ACK和NAK的3种可能性：

- 增加ACK机制，多确认一次，但是又无法保证增加的确认机制发送不出错
- 增加足够的检验和比特，不仅可以检查错误，还可以恢复差错。对于不丢失分组的信道可以直接解决问题
- 当发送方收到含糊不清的确认消息时，只需要重传当前数据分组，这需要引入 **冗余分组（duplication packet）**。冗余分组的困难在于接收方不知道它上次所发送的ACK或NAK是否被正确接收到，因此无法事先知道接收到的分组是新的还是一次重传

解决该问题的一个方法是再数组分组种添加一个新字段，标识发送数据分组的序号。



**3. 经具有比特差错的丢包信道的可靠数据传输：rdt 3.0**

假定会有比特差错和信道丢包现象。

发送方发送了一个分组，如果发送方接收不到接收方的ACK，则证明产生了发送分组丢包或者ACK信息丢包。发送方等待一段时间在进行重传。

如何判断等待时间？至少需要等待两端的往返时延和接收方处理时延；实际中选择一个时间值，如果没有收到ACK则重传，即时可能该分组的ACK没有丢失。这样信道上会出现冗余数据分组的可能性，可以通过标识的序号来处理冗余分组。

因为分组序号使用1比特，在0和1切换，rdt 3.0 也被称为 比特交替协议。

### 3.4.2 流水线可靠数据传输协议

停等协议因为需要等的动作，所以发送方的利用率很低，因此提出可以像流水线一样进行发送动作。

流水线带来的影响：

- 需要增加序号范围，连续发送的分组变多，大家需要有唯一序号。
- 协议的发送方和接收方两端也许必须缓存多个分组
- 使用 **回退N步（Go-Back-N，GBN）** 和 **选择重传（Selective Repeat，SR）**

### 3.4.3 回退N步

在 GBN 种，允许发送发发送多个分组而不需要等待确认，但它也受限于在流水线中未确认的分组不能超过某个最大的 N。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/GBN%E5%BA%8F%E5%88%97%E5%8F%B7.png)

基序号（base）定义为最早的未确认分组的序号，将下一个序号（nextseqnum）定义为最小的未使用序号（下一个待发分组序号）（图片颜色不太清楚，注意区分可用未发送和发送未确认）

$[0,base-1]$是发送并确认的分组

$[base,nextseqnum-1]$是发送，未确认分组

$[nextseqnum,base+N-1]$是未发送，即将要发送的分组

N被称为窗口长度，GBN协议也被称为 **滑动窗口协议（sliding-window protocol）**

发送方的三种事件：

- 上层调用：上层调用后，发送方先检查发送窗口是否满，如果已经满了，发送发将给上层返回信息，上层等一会再试。实际种发送方更可能缓存这些数据或者使用同步机制允许上层在窗口满时才调用。
- 收到ACK确认
- 超时事件：如果超时，发送方重传所有已发送但未被确认过的分组

接收方事件：

- 正确接收：序号n分组被接收到，返回一个ACK，将接收的分组发给上层
- 错误接受：序号乱序等情况，直接丢弃。即使n+1分组被正确接收，但是n分组还没来，也应当丢弃，n+1始终要重发，不必缓存

### 3.4.4 选择重传

GBN可能会因为单个的错误导致后面所有分组重传，如果窗口很大那么会因此丢失很多效率。

选择重传只需要重传接收方怀疑出错的分组。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E9%80%89%E6%8B%A9%E9%87%8D%E4%BC%A0SR.png)

发送方事件：

- 上层调用：从上层接收到数据，SR发送方检查下一个分组域好。在窗口内就打包发送，没有则将数据缓存，等待传输
- 超时：每个分组都有自己的定时器
- 收到ACK：收到ACK且分组在窗口内，SR发送方标记已接收，如果在窗口最左边，则窗口右移。如果右边扩充到需要发送的分组，则发送。

接收方事件：

- 序号在 $[rcv\_base,rcv\_base+N-1]$ 的分组被正确接收：收到的分组在窗口内，一个ACK返回。如果分组以前没收到过则缓存该分组；如果该分组的序号等于接收窗口的基序号（rcv_base），则将前面连续的分组交给上层。接收窗口向右移动。
- $[rcv\_base-N,rcv\_base-1]$的分组：产生一个ACK，即使之前接收过了。为了保证发送方的窗口能够向前滑动
- 其他情况忽略

也就是只要成功发送了ACK，不管接收方收到没，窗口都要滑动

## 3.5 面向连接的运输：TCP

### 3.5.1 TCP连接

TCP被称为是 **面向连接的（connection-oriented）**，这是因为一个应用进程可以开始向另一个引用进程发送数据之前，必须先进行 “握手”，即它们必须相互发送预备报文段，以建立确保数据传输的参数。

TCP连接提供的是 **全双工服务（full-duplex service）**：如果一台主机上的进程A与另一台主机上的进程B存在一条TCP连接，那么应用数据就可以从进程B流向进程A，进程A流向进程B。TCP连接也是点对点的，即在单个发送方与单个接收方之间的连接。

TCP连接建立前区分客户端和服务端，连接建立之后不区分。

**[三次握手](# 3.5.6 TCP连接管理)：**

1. 客户端向服务端发送建立连接的请求：SYN=1，ACK=0，seq=x；发送完毕进入到SYN-SEND状态
2. 服务端收到请求建立报文：如果确认连接，则返回：SYN=1，ACK=1，seq=y，ack=x+1；发送完毕后进入SYN-RCVD状态
3. 客户端收到确认报文：检查ACK=1，ack=x+1，若正确，发送确认报文，ACK=1，ack=y+1，seq=x+1；发送后进入ESTAB-LISHED状态，服务端收到后也进入该状态，此时TCP连接正式建立

前两次不能携带有效信息，第三次可以

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png)



进程将数据写入套接字，进入套接字代表数据正式被TCP接管，TCP将这些数据放入到 **发送缓存（send buffer）**种，这是三次握手设置的；接下来TCP不定时从缓存中拿出消息进行发送

TCP可从缓存中取出并放入报文段中的数据数量受限于 **最大报文段长度（Maximum Segment Size，MSS）**，通常根据最初确定的由本地发送主机发送的最大链路层帧长度（即 **最大传输单元（Maximum Transmission Unit，MTU）**）来设置。MSS要保证一个TCP报文段（经过IP封装）加上TCP/IP首部长度（通常40字节）将适合单个链路层帧。以太网和PPP链路层协议都具有1500字节的MTU，因此MSS的典型值为1460字节。MSS指报文段在应用层数据的最大长度，不是TCP首部的TCP报文段的最大长度。

### 3.5.2 TCP报文段结构

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/TCP%E6%8A%A5%E6%96%87%E6%AE%B5%E7%BB%93%E6%9E%84.png)

TCP报文段由首部字段和数据字段组成。数据字段包含一块应用数据。MSS限制了数据字段的最大长度

当TCP发送一个大文件，通常将该文件划分为长度为MSS的若干块。

首部字段（一般20字节）包含：

- 源端口号，目的端口号：用于多路复用和多路分解
- 序号字段和确认号字段：分别32比特
- 接收窗口字段：16比特，用于[流量控制](# 3.5.5 流量控制)
- 首部长度字段：4比特，指示了以32比特的字为单位的TCP首部长度
- 选项字段：可变长，该字段用于发送方于接收方协商最大报文段长度，或在高速网络环境下用作窗口调节因子时使用
- 标志字段：6比特，ACK，包括一个对已被接受报文段的确认；RST，SYN，FIN用于连接建立和拆除；PSH指示接收方将数据立即交给上层；URG表示报文段里存在被发送端的上层设置为“紧急”的数据，紧急数据由16比特的紧急数据指针字段指出。

**1. 序号和确认号**

这两个字段是可靠数据传输的关键部分。

序号是建立在字节流之上。假设500000字节数据，MSS为1000，因此第一个报文段的序号是0，第二个报文段的序号是1000，而不是1，同理第三个报文段是2000，而不是2。所以序号是数据部分的首字节

**主机A填充进报文段的确认号是主机A期望从主机B收到的下一字节的序号。**

例子1：假设主机A已经收到了主机B的编号为0-535的字节，现在要收到536，当它再发送给主机B时，报文段的确认号就是536。

例子2：主机A已经收到主机B发送的0-535和900-1000字节段，始终没有收到536字节段，因此此时确认号依旧是536。这种只确认流中的第一个字节得方式被称为累积确认。

RFC没有规定失序时该如何处理，可选方案：丢失失序段和保留失序段

实践中，一条TCP连接的双方均可随机地选择初始序号。这样做可以减少将那些仍在网络中存在地来自两台主机之间先前已终止的连接的报文段，误认为是新连接报文段的可能

**2. Telnet：序号和确认号的学习案例**



### 3.5.3 往返时间的估计与超时

TCP采用超时重传机制处理报文段的丢失问题。

**1. 估计往返时间**

报文段的样本往返时间RTT（表示为SampleRTT）就是从某报文段被发出（交给IP）到对该报文段的确认被收到之间的时间量。大多数TCP仅在某时刻做一次SampleRTT测量，而不是为每个报文段测量。仅为一个已发送但目前尚未被确认的报文段估计SampleRTT。TCP决不为已经被重传的报文段计算SampleRTT

因为路由器的拥塞和端系统负载优化，SampleRTT并不是典型值而要进行加工计算，TCP维持一个SampleRTT均值（称为EstimatedRTT）
$$
EstimatedRTT=(1-\alpha)*EstimatedRTT+\alpha*SampleRTT
$$
RFC 6298 给出 $\alpha$ 参考值 0.125

偏差值DevRTT
$$
DevRTT = (1-\beta)*DevRTT+\beta*|SampleRTT-EstimatedRTT|
$$
$\beta=0.25$

**2. 设置和管理重传超时间隔**
$$
TimeoutInterval = EstimatedRTT+4*DevRTT
$$
推荐初始值为 1 秒

### 3.5.4 可靠数据传输

收到三个冗余ACK，TCP就执行**快速重传**，即在该报文段的定时器过期之前重传丢失的报文段。

### 3.5.5 流量控制

TCP为它的应用程序提供了 **流量控制服务（flow-control service）**以消除发送方使接收方缓存溢出的可能性，使发送方的发送速率和接收方的接收速率相匹配。

TCP发送方也可能因为IP网络的拥塞而被遏制，这是发送方的 **拥塞控制（congestion control）。**

TCP通过让发送发维护一个窗口来提供流量控制。接收窗口用于给发送方一个指示，说明还有多少可用的缓存空间

假设主机A通过一条TCP连接向主机B发送一个大文件。主机B为该链接分配一个接收缓存，并用RcvBuffer表示大小。主机B上的应用进程不时地从该缓存中读取数据。定义以下变量：

- LastByteRead：主机B上的应用进程从缓存读出的数据流的最后一个字节的编号
- LastByteRcvd：从网络中到达的并且已经放入主机B接收缓存中的数据流的最后一个字节的编号

由于TCP不允许已分配缓存溢出，下面式子必须成立：
$$
LastByteRcvd-LastByteRead\leq RcvBuffer
$$
接收窗口用rwnd表示，根据缓存可用空间的数量来设置：
$$
rwnd=RcvBuffer-[LastByteRcvd-LastByteRead]
$$
![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/rwnd.png)

rwnd空间是随时间变化的

主机B通过把当前的rwnd值放入它发给主机A的报文段接收窗口字段中，通知主机A它还有多少缓存空间。开始时主机B设定 $rwnd=RcvBuffer$

主机A跟踪LastByteSent和LastByteAcked，需要保证这两个数据的差值在rwnd范围内
$$
LastByteSent-LastByteAcked\leq rwnd
$$
这样主机A就不会使主机B的缓存溢出。

如果主机B发送给主机A rwnd=0，且主机B不再给主机A发送报文。这样主机B清空自己的缓存，但是并不会向主机A发送rwnd>0的报文段，这样主机A不知道主机B有可用空间，就会有一直阻塞。

为了解决这个问题，当rwnd=0，主机A会继续发送一个字节的数据报文，这段报文被主机B接收确认，并开始清空缓存，并发送新的rwnd值。

###                                                                                                            3.5.6 TCP连接管理

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E5%AE%A2%E6%88%B7%E7%AB%AFTCP%E7%8A%B6%E6%80%81%E6%9C%BA.png)

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E6%9C%8D%E5%8A%A1%E7%AB%AFTCP%E7%8A%B6%E6%80%81%E6%9C%BA.png)

比 [3.5.1更详细的三次握手](# 3.5.1 TCP连接)

1. 首先客户端TCP向服务端TCP发送一个特殊TCP报文段，不包含应用层数据，其中SYN=1.客户端会随机的选择一个初始序号client_isn，并将编号放置于起始的TCP SYN报文段的序号字段中。该报文段经过IP封装为数据包发送给服务器。**进入SYN_SENT**
2. 服务器提取TCP SYN报文段，为该TCP连接分配TCP缓存和变量，并向客户发送允许链接报文段。这个连接报文段也不包含应用层数据。但是会包含，SYN=1，TCP报文段的首部的确认号字段被置为client_isn+1，然后服务器选择自己的初始序号server_isn，并放在报文段首部的序号字段中。这段报文表明：我收到了建立连接请求，同意建立连接。也被称为STNACK报文段。客户端进入 **ESTABLISHED**，服务端**进入 SYN_RCVD**
3. 在收到SYNACK报文段后，客户端也要分配缓存和变量。客户端向服务器发送另外一个报文段，该报文段对允许链接的报文进行回应，其中server_isn+1。连接已经建立，SYN=0.这次可以携带数据。服务端进入 **ESTABLISHED**

四次挥手：

1. 客户端向服务器发送关闭连接报文，其中FIN=1，客户端进入FIN-WAIT-1状态
2. 服务器接收到该报文后，向客户端发送一个确认报文ACK，收到报文序号+1，服务端进入CLOSED-WAIT
3. 服务器再向客户端发送关闭连接报文，同样FIN=1，客户端接收到进入FIN-WAIT-2状态
4. 客户端发送确认关闭报文。进入 **TIME_WAIT** 等待一段时间再关闭

SYN洪泛攻击





## 3.6 拥塞控制原理

### 3.6.1 拥塞原因与代价

**1. 情况1：两个发送方和一台无限大缓存的路由器**

极端理想化情况下，拥塞网络的代价，当分组到达速率接近链路容量时，分组经历巨大的排队时延。

接收方发回确认就可以放到缓存中，但是处理的慢，都在排队

**2. 情况2：两个发送方和一台有限缓存的路由器**

发送方遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本。

接收方缓存满了，多个被丢弃，发送方最终重传

**3. 情况3：四个发送方和具有有限缓存的多台路由器及多跳路径**

当一个分组沿一条路径被丢弃时，每个上有路由器用于转发该分组到丢弃该分组而使用的传输容量都被浪费了。



### 3.6.2 拥塞控制方法

根据网络层是否为运输层拥塞提供了显式帮助，来区分拥塞控制方法：

- 端到端拥塞控制：网络层没有为运输层拥塞控制提供显式的支持。即使网络中存在拥塞，端系统也必须通过对网络行为（分组丢失与时延）的观察来推断。[TCP必须通过端到端的方法解决拥塞控制](# 3.7 TCP拥塞控制)，因为IP层不会向端系统提供有关网络拥塞的反馈信息。TCP报文的丢失（超时或者3次冗余确认）被认为是一种网络拥塞迹象。TCP会相应地减少其窗口长度。
- 网络辅助地拥塞控制：在网络辅助地拥塞控制中，网络层构件向发送发提供关于链路中地拥塞情况。用于ATM和ABR控制中。拥塞信息从网络反馈地两种方式：直接反馈由网络路由器直接发送给发送方，采用了一种阻塞分组形式；第二种是路由器标记或更新从发送方流向接收方地分组中地某个字段来指示拥塞产生，接收方就会向发送方发出拥塞指示。

### 3.6.3 网络辅助的拥塞控制例子：ATM ABR拥塞控制

异步传递方式（ATM）

可用比特率（ABR）

ATM ABR中地拥塞控制算法，即一种采用网络辅助方法解决拥塞控制地协议。

ATM基本上采用一种面向虚电路（VC）的方法来处理分组交换，这意味着从源到目的地路径上的每台交换机将维护有关源到目的地VC的状态。这种逐个VC的状态允许交换机跟踪各个发送方的行为，并采取特定源的拥塞控制动作。

ABR已被设计成一种弹性数据传输服务。当网络轻载时，ABR服务会充分利用空闲带宽；当网络拥塞时，ABR服务会将其传输速率抑制为某些预先确定的最小传输速率。

对于ATM ABR服务，数据信源从源经过一系列中间交换机传输到目的地。在数据信元中夹杂着所谓的 **资源管理信元（Resource-Management cell，RM信元）**；这些RM信元可被用来在主机和交换机之间传递与拥塞相关的信息。当一个RM信元到达目的地时，它将被调转方向并向发送发发送。交换机也有可能自己产生一个RM信元，并将该RM信元直接发送给源。因此RM信元可用来提供直接网络反馈和经由接收方的网络反馈。

ATM ABR 拥塞控制是一种基于速率的方法，即发送方明确地计算处它所能发送的最大速率，并据此对自己进行相应地调整。ABR提供三种机制用于从交换机向接收方发送与拥塞相关地信令信息：

- EFCI比特：每个数据信源都包含1比特地 **显式转发拥塞指示（Explicit Forward Congestion Indiacation，EFCI）比特**。某拥塞网络地网络交换机可把一个数据信元中地EFCI比特设置为1来向目的主机发送网络已经拥塞地指令。其目的地必须检查所有收到地数据信元中地EFCI比特。当一个RM信元到达目的地时，如果多数近来收到的数据信元地EFCI比特都被置为1，则目的地就会将RM信元地拥塞指示比特（CI比特）置为1，并将该RM信元发送回发送方。使用数据信元中地EFCI比特和RM信元中的CI比特，发送方因而能在网络交换机拥塞时得到通知。
- CI和NI比特。发送方到接收方的RM信元是夹杂在数据单元中的。RM信元的夹杂比率是一个可调参数，默认值是32个数据信元中有一个RM信元。这些RM信元中有一个 **拥塞指示比特（Congestion Indication， CI）** 和 **无增长比特（No Increase，NI）**，这两个比特可被一台拥塞的交换机设置。特别是，交换机可以在轻微拥塞时将经过的RM信元中的NI比特置为1，在严重拥塞时，把CI比特置为1。当目的主机收到一个RM信元时，它将该RM信元发回给发送方，而保持CI与NI比特不变（除了CI比特也许会因为上面描述的EFCI机制而由目的端置为1之外）
- ER的设置。每一个RM信元还包含一个两字节的 **显式速率（Explicit Rate，ER）字段**。一个拥塞的交换机也许会降低经过的RM信元中ER字段所包含的值。以这种方式，ER字段将被设置为在源至目的地的路径上的所有交换机中的最小可支持速率。





## 3.7 TCP拥塞控制

TCP发送发如果感知没有拥塞，则会增加发送速率；如果拥塞，则会降低发送速率。

[3.5.5 流量控制](# 3.5.5 流量控制)介绍了TCP的流量控制原理（rwnd，接收方未被确认的数据量间接地限制了发送方的发送速率）

问题：

- TCP发送方如何限制发送速率
- TCP发送方如何感知拥塞
- TCP发送方感知到拥塞后怎么改变发送速率

原则：

- 丢包事件意味着拥塞，应该降低发送方速率：一个超时事件或者四个确认（一个初始ACK和三个冗余ACK）被解释为丢包事件。该问题是TCP发送方应当如何减小它的拥塞窗口（cwnd）长度，从而减小发送速率，应对丢包事件
- 一个确认报文段指示该网络正在向接收方交付发送发的报文段。因此对先前未确认的报文段确认到达时可增加发送速率。确认到达即报文段成功交付给接收方，网络不拥塞，可以增大拥塞窗口，增加发送速率。
- 带宽探测。上面增加速率和减少速率也被称为带宽探测。

TCP拥塞控制算法：包括 慢启动、拥塞避免、快速恢复三个部分。慢启动和拥塞避免是TCP的强制部分。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/TCPFSM.png)

> 慢启动：
>
> 先发送一个MSS（最大报文段长度），收到确认ACK就翻倍，直到到达慢启动阈值。进入拥塞避免状态
>
> 拥塞避免：没经过RTT（往返时间，收到一个ACK确认），cwnd就增加一个MSS字节
>
> 快速恢复：对于引起快速恢复状态的缺失报文段，对收到的每个冗余的ACK，cwnd值增加一个MSS。最终当丢失报文段的一个ACK到达时，TCP降低cwnd后进入拥塞避免。
>
> 快速重传机制：如果发送方接收到对相同数据的3个冗余ACK，进行快速重传，在该报文段的定时器过期之前就重传丢失的报文段。
>
>  
>
> 慢启动到拥塞避免：cwnd达到慢启动阈值
>
> 快速恢复到拥塞避免：收到新的ACK
>
> 共同的机制：
>
> 如果遇到丢包超时时间，转换到慢启动；慢启动阈值变为cwnd/2，cwnd=1
>
> 如果收到3个冗余的ACK，就转到快速恢复；慢启动阈值变为cwnd/2，cwnd=慢启动阈值+3*MSS



**1. 慢启动**

一个TCP连接最初设置为一个MSS。每当收到所有确认就翻倍发送MSS，如下图

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/main/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/TCP%E6%85%A2%E5%90%AF%E5%8A%A8.png)

何时停止增加？

- 第一种：收到一个丢包事件，TCP将cwnd设置为1并重新开始慢启动；将第二个状态变量的值ssthresh（慢启动阈值）设置为cwnd/2
- 第二种：当超过阈值就停止慢启动，转到拥塞避免模式
- 第三种：如果检测到三个冗余ACK，TCP执行[快速重传](# 3.5.4 可靠数据传输)并进入快速恢复状态。

**2. 拥塞避免**

一旦进入拥塞避免状态，cwnd值大约是上次遇到拥塞时的值的一半。这时候采用保守的方式增加cwnd。

一种通用的方式是，每收到一个确认，增加MSS（MSS/cwnd）字节。例如，如果MSS是1460字节并且cwnd是14600字节，则在一个RTT内发送10个报文段。每个ACK增加1/10MSS的拥塞窗口长度，因此收到10个报文段确认后增加一个MSS

何时停止这样的线性增长？

当丢包事件出现，ssthresh的值被设置为cwnd值的一半，接下来进入快速恢复状态

**3. 快速恢复**

在快速恢复中，对于引起TCP进入快速恢复状态的缺失报文段，对收到的每个冗余的ACK，cwnd的值增加一个MSS。最终，当丢失报文段的一个ACK到达时，TCP降低cwnd后进入拥塞避免状态。

如果出现超时事件，快速恢复在执行如同慢启动和拥塞避免中相同的动作后，迁移到慢启动状态；

如果出现丢包事件，cwnd值被设置为1个MSS，并且ssthresh的值设置为cwnd值的一半。



**4. GBN or SR**

[CSDN上对于TCP、GBN、SR的一些理解](https://blog.csdn.net/u013427969/article/details/52725581)



# 第四章 网络层

我们将对网络层的 **转发（forwarding）** 功能和 **路由选择（routing）** 功能做重要区分。

网络层三个重要组成部分：

- IP协议
- 路由选择
- 差错控制

## 4.1 概述



### 4.1.1 转发和路由选择

两种重要的网络层功能：

- 转发：当一个分组到达路由器的一条输入链路时，路由器必须将该分组移动到适当的输出链路。
- 路由选择：当分组从发送方流向接收时，肉络层必须决定这些分组所采用的路由或路径。计算这些路径的算法被称为 **路由选择算法（routing algorithm）**

转发指将分组从一个输入链路接口转移到适当的输出链路接口的路由器本地。

路由选择是指网络范围的过程，以决定分组从源到目的地所采用的端到端路径。

每台路由器具有一张 **转发表（forwarding table）**。路由器通过检查到达分组首部字段的值来转发分组，然后使用该值路由器的转发表中索引查询。存储在转发表项中的该分组的目的地指出了该分组将被转发的路由器的输出链路接口。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E8%B7%AF%E7%94%B1%E8%BD%AC%E5%8F%91%E5%9B%BE.png)

### 4.1.2 网络服务模型

**网络服务模型（network servie model）**定义了分组在发送与接收端系统之间的端到端运输特性。

当运输层向网络层传递一个分组时，能由网络层提供的特定服务包括：

- 确保交付：该服务确保分组将最终到达其目的地。
- 具有时延上界的确保交付：有时效限制

能够为给定和源和目的地之间的分组流提供下列服务：

- 有序分组交付：
- 确保最小带宽：在低于特率的速率传输比特，则分组不丢失，且保证时延
- 确保最大时延抖动：确保位于发送方的两个相继分组之间的时间量等于再目的地接收它们之间的时间量（或者间隔变化不会超过某个设定值）
- 安全性服务：使用仅由源和目的主机所知晓的一个秘密会话密钥，在源主机中网络层能够加密向目的主机发送的所有数据报负载。在目的主机中的网络层则能够负责解密该负载

## 4.2 虚电路和数据报网络

网络层也有无连接服务或面向连接的服务。

- 在网络层中，这些服务是由网络层向运输层提供的主机到主机的服务。在运输层中，这些服务则是运输层向应用层提供的进程到进程的服务。
- 网络层仅同时提供一种服务（无连接或者面向连接），仅在网络层提供连接服务的计算机网络称为 **虚电路（Virtual-Circuit，VC）**；仅在网络层提供无连接服务的计算机网络称为 **数据报网络（datagram network）**。

### 4.2.1 虚电路网络

一条虚电路的组成如下：

1. 源和目的主机之间的路径（一系列链路和路由器）
2. VC 号，沿着该路径的每段链路的一个号码
3. 沿着该路径的每台路由器中的转发表表项。

属于一条虚电路的分组将在它的首部携带一个VC号。因为一条虚电路在每条链路上可能具有不同的VC号，每台中间路由器必须用一个新的VC号替代每个传输分组的VC号。

如下图，主机 A 请求该网络在它自己与主机 B 之间创建一条虚电路。同时假定该网络为该虚电路选择路径 A-R1-R2-B，并为这3条链路分配VC号 12、22和32。分组离开主机A，此时首部VC号是12；在R1中查询路由转发表知道从2口出，VC号为22，即离开R1的VC号为22；达到R2后查表得VC号为32；最后到达B

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/VC.png)

路由转发表类似这样：

<table>
    <tr>
    	<th>如接口</th>
        <th>入VC号</th>
        <th>出接口</th>
        <th>出VC号</th>
    </tr>
    <tr>
    	<td>1</td>
        <td>12</td>
        <td>2</td>
        <td>22</td>
    </tr>
    <tr>
    	<td>2</td>
        <td>63</td>
        <td>1</td>
        <td>18</td>
    </tr>
    <tr>
    	<td>3</td>
        <td>7</td>
        <td>2</td>
        <td>17</td>
    </tr>
    <tr>
    	<td>4</td>
        <td>97</td>
        <td>3</td>
        <td>87</td>
    </tr>
</table>


无论何时跨越一台路由器创建一条新的虚电路，转发表就增加了一个新 表项。无论何时终止一条虚电路，沿着该路径每个表中得相应项将被删除。

一条链路使用相同VC号的缺点：

- 逐链路代替该号码减少了在分组首部中VC字段的长度
- 通过允许沿着该虚电路路径每条链路上有不同的VC号，简化了虚电路的建立。

虚电路网络中，该网络的路由器必须为进行中的连接维持 **连接状态信息（connection state information）**，就是VC号等

虚电路中的3个阶段：

- 虚电路建立：在建立阶段，发送运输层与网络层联系，指定接收方地址，等待网络建立虚电路。网络层决定发送方与接收方之间的路径，即该虚电路的所有分组要通过一系列链路与路由器。网络层也为沿着该路径的每条链路决定一个VC号。最后，网络层在沿着路径的每台路由器的转发表中增加一个表项，在虚电路建立期间，网络层还可以预留该虚电路路径上的资源。
- 数据传送：一旦建立了虚电路，分组就可以开始沿该虚电路流动了

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E8%99%9A%E7%94%B5%E8%B7%AF%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5.png)

- 虚电路拆除：当发送方（或接收方）通知网络层它希望终止该虚电路时，就启动这个阶段。然后网络层通常将通知网络另一侧的端系统结束呼叫，并更新路径上每台分组路由器中的转发表以表明该虚电路已不存在了。

端系统向网络发送指示虚电路启动与终止的报文，以及路由器之间传递的用于建立虚电路（修改路由表中的连接状态）的报文，他们被称为 **信令报文（signaling message）**，用来交换这些保温的协议通常称为 **信令协议（signaling protocol）**。



### 4.2.2 数据报网络

在数据报网络中，每当一个端系统要发送分组，它就为该分组上目的端系统的地址，然后将分组推进网中。

当分组从源到目的地传输，它通过一系列路由器传递。这些路由器中的每 台都使用分组的目的地址转发该分组。每台路由器有一个将目的地址映射到链路接口的换发表；当分组到达路由器时，路由器使用该分组的目的地址在转发表中查找适当的输出链路接口。然后路由器有意将分组向该输出链路接口转发。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E6%95%B0%E6%8D%AE%E6%8A%A5%E7%BD%91%E7%BB%9C.png)

**转发规则P210**

### 4.2.3 虚电路和数据报的由来



## 4.3 路由器工作原理

**转发功能（forwarding function）**即实际将分组从一台路由器的入链路传送到适当的出链路。



### 4.3.1 输入端口

**三态内容可寻址存储器（Tenary Content Address Memory，TCAM）**



### 4.3.2 交换结构



### 4.3.3 输出端口



### 4.3.4 何处出现排队



### 4.3.5 路由选择控制平面



## 4.4 网际协议：因特网中的转发和编址

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/networklayer.png)

### 4.4.1 数据报格式

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/IPv4.png)

IPv4数据报中的关键字段如下：

- 版本号：4比特，规定了协议版本号
- 首部长度：4比特，一般IP数据报首部20字节，如果有选项字段就需要用首部长度来确定数据从哪开始
- 服务类型：区分实时数据报、非实时流量、低时延数据报等等
- 数据报长度：16比特，IP数据报的总长度（首部加上数据），以字节记
- 标识、标志、片偏移：IP分片相关
- 寿命：寿命（Time-To-Live，TTL）字段用来确保数据报不会永远再网络中循环。每当数据报由一台路由器处理时，该字段值减1，若TTL字段减为0，该数据报必须废弃
- 协议：该字段仅在一个IP数据报到达目的地才会有用。该字段指示了IP数据报的数据部分应该交给哪个特定的运输层协议。
- 首部校验和：首部检验和用于帮助路由器检测收到的IP数据报中的比特错误。首部校验和是这样计算的：将首部中的每2个字节当作一个数，用反码运算对这些数求和。
- 源和目的IP地址：
- 数据（有效载荷）：

**IP数据报分片**

一个链路层帧能承载的最大数据量叫做 **最大传送单元（Maximum Transmission Unit，MTU）**

因为每个IP数据报封装在链路层从一台路由器传输到下一台路由器，故链路层协议的MTU严格地限制着IP数据报的长度。而不同的路径上可能使用不同的链路层协议，从而导致MTU不同。因此需要**分片**操作，将长的IP数据报分为多个较小的 **片**。

片在到达目的地前需要重新组装，这个组装过程放在端系统中。

端系统在组装时，需要确定这些数据报是否是较大数据报的片；如果是片，还要确定何时收到最后一片，并怎样拼接数据报。因此有了首部的 **标识、标志和片偏移**



### 4.4.2 IPv4编址

每个IP地址长度为32比特，因此总共有 $2^{32}$ 个可能的IP地址。一般按照点分十进制书写。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/%E6%8E%A5%E5%8F%A3%E5%9C%B0%E5%9D%80%E5%92%8C%E5%AD%90%E7%BD%91.png)

图中一台路由器有三个链路接口。左侧都有一个223.1.1.xxx 地址，意味着IP地址左侧24位比特是相同的。这三台主机和路由器形成了一个子网。IP编址为子网分配了一个地址：223.1.1.0/24，/24称为子网掩码，指示了32比特中，最左侧24位是子网地址。

因特网的地址分配策略被称为 **无类别域间路由选择（Classless Interdomain Routing，CIDR）**

CIDR出现之前，IP地址的网络部分被限制为长度为8、16、24比特，这是一种称为 **分类编址（classful addressing）** 的编址方案。

- A类网址：/8
- B类网址：/16
- C类网址：/24

回环地址：127.0.0.1

广播地址：255.255.255.255 将消息广播给子网中的所有主机

**1. 获取一块地址**

**2. 获取主机地址：动态主机配置协议**

**动态主机配置协议（Dynamic Host Configuration，DHCP）**，网络管理员能够配置DHCP，以使某给定主机每次与网络连接时能得到一个相同的IP地址，或者某主机将被分配一个临时的IP地址。

由于DHCP具有能够将主机自动连接进一个网络的能力，又称为 **即插即用协议（plug-and-play protocol）**

DHCP分配给新设备地址的过程如下：

- DHCP服务器发现：一台新设备需要先与DHCP服务器交互，可以通过一个 **DHCP发现报文（DHCP discover message）** 完成，客户在UDP分组中向端口67发送该报文。因为不知道要发给谁，所以使用广播地址（255.255.255.255）并使用本机的源地址0.0.0.0。新主机将该IP数据报传递给链路层，链路层然后将该帧广播到所有与该子网连接的子网。
- DHCP服务器提供：DHCP服务器收到发现报文时，用一个 **DHCP提供报文（DHCP offer message）** 向客户作出响应，仍然使用广播地址。报文中包含事务ID、推荐IP地址、网络掩码以及 **IP地址租用期（address lease time）**
- DHCP请求：新主机向选中的服务器发送一个 **DHCP请求报文（DHCP request message）** 进行响应，回显配置参数。
- DHCP ACK：服务器用 DHCP ACK 报文（DHCP ACK message） 对DHCP请求报文进行相应，证实所要求的参数。

**3. 网络地址转换**

随着子网的设备逐渐增多，ISP划分给该子网的地址段会逐渐不够用，已经没法再扩大分配连续的地址段，所以有了 **网络地址转换（Network Address Translation，NAT）**

通过NAT转换，子网内的设备对外都拥有同一个IP地址，外网该怎么区分子网内的设备呢？

NAT路由器上有一个 **NAT转换表（NAT tranalstion table）**，并且包含了IP地址和端口号

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/NAT.png)

步骤：

- 从子网主机10.0.0.1请求128.119.40.186的Web服务器，端口80。主机10.0.0.1为其指派了一个任意端口号3345并将该数据报发送到LAN中
- NAT路由器接收到数据报并为该数据报生成一个新的源端口号5001，将源IP替换为138.76.29.7，且端口号替换为5001
- Web服务器回响的报文发送给138.76.29.7:5001，NAT接收到后根据转换表转换为10.0.0.1:3345

**4. UPnP**



### 4.4.3 因特网控制报文协议

因特网控制报文协议（Internet Control Message Protocol），被主机和路由器用来彼此沟通网络层的信息。典型应用是差错报告。

ICMP通常被认为是IP的一部分，但是从体系结构上讲是位于IP之上的，因为ICMP报文是承载在IP分组中的。也就是ICMP作为IP有效载荷。就像TCP和UDP报文段作为IP有效载荷被承载以及将收到的报文解析并给到TCP和UDP一样。



### 4.4.4 IPv6



### 4.4.5 涉足IP安全性



## 4.5 路由选择算法

主机通常直接与一台路由器相连接，该路由器即为该主机的 **默认路由器（default router）**，又称为该主机的 **第一跳路由器（first-hop router）**。每当主机发送一个分组时，该分组被传送给它的默认路由器。我们将源主机的默认路由器称为 **源路由器** ，把目的主机的默认路由器称为 **目的路由器**。

一条好的路径就是最低费用路径，（图的最短路径算法）

- [全局式路由选择算法（global routing algorithm）](# 保留链接)：得知全局性、完整的所有的节点的连通性以及费用，这些信息需要在计算之前都得到。具有全局状态信息的算法被称为 **链路状态(Link State, LS)算法**
- [分散式路由选择算法（decentralized routing algorithm）](# 保留链接)：以迭代、分布式得方式计算最低费用。开始计算时没有完全拥有所有费用信息，每个节点仅有与其直接相连链路的费用。这种方式称为 **距离向量（Distance- Vector, DV）**
- [静态路由选择算法（static routing algorithm）](# 保留链接)：随着时间流逝，路由的变化是非常缓慢的，通常是人工干预进行调整
- [动态路由选择算法（dynamic routing algorithm）](# 保留链接)：能够当网络流量负载或拓扑发送变化时改变路由选择路径。一个动态算法可周期性地运行或直接响应拓扑或链路费用地变化而运行，容易收到路由选择循环、路由振荡之类地问题地影响。
- [负载敏感算法（load-sensitive algorithm）](# 保留链接)：链路费用会动态地变化以反映出底层链路地当前拥塞水平。
- [负载迟钝算法（load-insensitive algorithm）](# 保留链接)：

### 4.5.1 链路状态路由选择算法

Dijkstra



### 4.5.2 距离向量路由选择算法

**距离向量（Distance- Vector，DV）**算法是一种迭代的、异步的和分布式的算法。

令 $d_x(y)$ 是从结点 $x$ 到结点 $y$ 的最低费用路径的费用。则该最低费用与著名的 Bellman-Ford 方程相关：$d_x(y)=min_v{c(x,v)+d_v(y)}$, $c(x,v)$ 是 $x$ 到 $v$ 结点的代价

Bellman-Ford 方程的另一个重要实际贡献是它提出了将在DV算法中发生的邻居到邻居通信的形式。

其基本思想如下：每个节点 $x$ 以 $D_x(y)$ 开始，对在 $N$ 中的所有结点，估计从它自己到结点 $y$ 的最低费用路径的费用。令 $D_x(y)={D_x(y):y\in N}$ 是结点 $x$ 的距离向量，该向量是从 $x$ 到在 $N$ 中的所有其他节点 $y$ 的费用估计的向量。使用 DV 算法，每个节点 $x$ 维护下列路由选择信息：

- 对每个邻居 $v$，从 $x$ 到直接相连邻居 $v$ 的费用 $c(x,v)$
- 结点 $x$ 的距离向量，即 $D_x(y)={D_x(y):y\in N}$ ， 包含了 $x$ 到 $N$ 中所有目的地 $y$ 的费用的估计值。
- 它的每个邻居的距离向量，即对 $x$ 的每个邻居 $v$，有 $D_x(y)={D_x(y):y\in N}$

在该算法中。每个节点不时地向它的每个邻居发送它的距离向量副本。当该节点 $x$ 从它的任何一个邻居 $v$ 接收到一个新距离向量，它保存 $v$ 的距离向量，然后使用 Bellman-Ford 方程更细他自己的距离向量。

如果 $x$ 的距离向量因这个更新步骤而改变，结点 $x$ 接下来将向它的每个邻居发送其更新后的距离向量。

**1. 距离向量算法：链路费用改变与链路故障**

遇到路由选择环路

无穷计数问题

**2. 距离向量算法：增加毒性逆转**

通过 **毒性逆转（poisoned reverse）** 技术可以避免上面的情况。

如果 $z$ 通过 $y$ 路由选择到目的地 $x$，则 $z$ 将通告 $y$ ，它（z）到 $x$ 的距离是无穷大的，即 $z$ 将向 $y$ 通告 $D_z(x)=\infty$（即使 $z$ 实际上知道 $D_z(x)=5$）。这样 $y$ 永远不会经过 $z$ 寻找 $x$



### 4.5.3 层次路由选择

上面两种路由选择算法在网络规模（路由器数量不断增多）增大或者有些组织需要自己的路由时会出现问题

这个问题可以通过将路由器组织进**自治系统（Autonomous System，AS）**来解决，每个AS由以组通常处在相同管理控制下的路由器组成。在相同层级运行同样的路由算法，且拥有彼此的信息，在一个自治系统内运行的路由选择算法叫做 **自治系统内部路由选择协议（intra-autonomous system routing protocol）**。每个AS必须是互联的，因此在一个AS内有一台或者多态路由被称为 **网关路由**



## 4.6 因特网中路由选择



## 4.6 因特网中路由选择

AS内部路由选择协议用于确定子啊一个AS内执行路由选择的方式。AS内部路由选择协议又称为 **内部网关协议（interior gateway protocol）**。

**路由选择信息协议（Routing Information Protocol，RIP）**和**开放最短路径有先（Open Shortest Path First，OSPF）**

### 4.6.1 因特网中自治系统内部的路由选择：RIP

路由选择信息协议（Routing Information Protocol，RIP）

RIP是一种距离向量协议，很像 DV 算法。在RIP中，链路费用使用跳数来标记，每条链路的费用为1。

![](https://raw.githubusercontent.com/LiMuwenan/PicBed/master/img/dev/ComputerNetwork/%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B/RIP.png)

一条路径的最大费用被限制为15，因此RIP的使用限制在网络直径不超过15跳的自治系统内。

在RIP中，路由选择更新信息在邻居之间通过使用 **RIP响应报文（RIP response message）**来交换，大约每30秒相互交换一次。由一台路由器或主机发出的响应报文包含了一个该AS内的多大25个目的子网列表，以及发送方到其中每个子网的距离。响应报文又被称作 **RIP通告（RIP advertisement）**。一台路由收到另一台路由器的通告后更新路由转发表

如果一台路由器超过180秒没有从邻居听到报文，则该邻居不再被认为是可达的，要么死机要么链路中断。当这种情况发生，RIP修改本地路由表，然后向相邻活着的路由器发送通告传播该信息。

路由器可以通过使用RIP请求报文来请求邻居到指定目的地的费用；在UDP上使用520端口发送RIP请求报文与响应报文；封装在标准IP数据报中的UDP报文段在路由器之间传输。

RIP使用一个位于网络层协议（IP）之上的运输层协议（UDP）来实现网络层功能（路由选择算法）



### 4.6.2 因特网中自治系统内部的路由选择：OSPF

开放最短路径优先（Open Shortest Path First，OSPF）

OSPF通常被设置在上层的ISP中，RIP通常设置在下层ISP和企业网中。

OSPF的核心就是一个使用洪泛链路状态信息的链路状态协议和一个Dijkstra最低费用路径算法。

使用OSPF，一台路由器构建了一幅关于整个自治系统的完整拓扑图。于是路由器在本地运行Dijkstra的最短路径算法，以确定一个以自身为根结点的到所有子网的最短路径树。

使用OSPF，路由器向自治系统内所有其他路由器广播路由器选择信息，而不仅仅是向其他相邻路由器广播。每当一条链路的状态发生变化时，路由器就会广播链路状态信息。即使链路状态未发生变换，它也要周期性的（至少每隔30分钟一次）广播链路状态。

OSPF优点：

- 安全：能够鉴别OSPF路由器之间的交换。使用鉴别，仅有受信任的路由器能参与一个AS内的OSPF协议，因此可防止恶意入侵者将不正确的的信息注入路由器表内。
- 多条相同费用路径：当到达某目的地的多条路径具有相同的费用时，OSPF允许使用多条路径
- 对单播与多播路由选择的综合支持：多播 OSPF 提供对 OSPF 的简单扩展，以便提供多播路由选择
- 支持在单个路由选择域内的层次结构：也许 OSPF 最重要的优点是具有按层次结构构造一个自治系统的能力

在一个区域内，一台或多态 **区域边界路由器（area border router）** 负责为流向该区域意外的分组提供路由选择。最后，在AS内只有一个OSPF区域配置成 **主干（backbone）** 区域。

### 4.6.3 自治系统间的路由选择：BGP

跨越多个AS的源和目的对之间是如何确定路径的。

**边界网关协议（Broder Gateway Protocol，BGP）** 为每个AS提供了进行以下工作的手段：

1. 从相邻AS处获得子网可达性信息
2. 向本AS内部的所有路由器传播这些可达性信息
3. 基于可达性信息和AS策略，决定到达子网的好路由

BGP使得每个子网向因特网的其余部分通告自己的存在。



**1. BGP基础**

在BGP中，路由器对通过使用179端口的半永久TCP连接来交换路由选择信息，对于每条直接连接位于两个不同AS中的路由器，都有这样的BGP TCP连接。一个AS中的路由器之间也有TCP连接。

对于每条TCP连接，位于该连接端点的两台路由器称为 **BGP对等方**，沿着该连接发送所有 BGP 报文的 TCP 连接称为 **BGP会话**。跨越两个AS的BGP会话称为 **外部BGP（eBGP）会话**，在同一个AS中的称为 **内部BGP（iBGP）会话**



在BGP中，目的地不是主机而是CDIP化的前缀，每个前缀标识一个子网或者一个子网的集合。

AS之间会互相发送前缀列表进行可达性分析



**2. 路径属性和BGP路由**

在BGP中，一个自治系统由一个全局唯一的**自治系统号（Autonomous System Number,ASN）**标识。特殊的AS称为桩AS没有这个ASN，这种AS仅承载源地址或目的地址为本AS的流量。

当一台路由器通过BGP会话通告一个前缀时，它在前缀中包括一些 **BGP属性**，带有前缀的属性被称为一条 **路由**。两个重要的属性是 AS-PATH 和 NEXT-HOP

- AS-PATH：该属性包含了前缀的 通告已经通过的那些AS。当一个前缀传送到一个AS时，将该AS的ASN增加到AS-PATH中。使用该属性可以检测和防止循环通告
- NEXT-HOP：在AS间和AS内部路由选择协议之间提供重要链路后，该属性是一个开始某AS-PATH的路由接口

这里没看完



**3. BGP路由选择**

如果对相同前缀存在两条或多条路由，则BGP顺序地调用下列消除规则，直到留下一条路由：

- 路由被指派一个本地偏好值作为他们的属性值一：一条路由的本地偏好可能由该路由器设置或可能在相同AS中的另一台路由器学习到。这是一条由AS的网络管理员决定的决策。具有最高本地偏好值得路由将被选择
- 在余下得路由中，具有最短AS-PATH得路由将被选择。如果该规则是路由选择的唯一规则的话，则BGP将使用一种距离向量算法来决定路径，其中距离测度使用AS跳的数目而不是路由器跳的数目
- 在余下的路由中，将选择具有最靠近NEXT-HOP路由器的路由。这里最靠近指的是具有最低费用路径的路由，它由AS内部算法决定
- 余下的路由中，该路由器使用BGP标识符选择路由

**4. 路由选择策略**



## 4.7 广播和多播路由选择



### 4.7.1 广播路由选择算法



### 4.7.2 多播











# 第5章 链路层：链路、接入网和局域网



# 第6章 无线网络和移动网络



# 第7章 多媒体网络



# 第8章 计算机网络中的安全



# 第9章 网络管理